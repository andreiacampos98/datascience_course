{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19c1b88",
   "metadata": {},
   "source": [
    "# Building a predictive model - Part II\n",
    "\n",
    "[4. Model & Assess (Modelling and Assessment)](#1st-bullet)<br>\n",
    "- [4.1. Model Selection](#2nd-bullet)<br>\n",
    "    - [4.1.1. Compare different algorithms and select the most promising ones](#3rd-bullet)<br>\n",
    "- [4.2. Model Optimization](#4th-bullet)<br>\n",
    "    - [4.2.1. K-Nearest Neighbors](#5th-bullet)<br>\n",
    "    - [4.2.2. Decision Trees](#6th-bullet)<br>\n",
    "        - [4.2.2.1. RandomizedSearchCV](#7th-bullet)<br>\n",
    "        - [4.2.2.2. GridSearchCV](#8th-bullet)<br>\n",
    "    - [4.2.3. Select the winner model](#10th-bullet)<br>\n",
    "        - [4.2.3.1. Compare the performance](#11th-bullet)<br>\n",
    "        - [4.2.3.2. Plot a ROC Curve](#12th-bullet)<br>\n",
    "        - [4.2.3.3. Change the threshold](#13th-bullet)<br>\n",
    "        \n",
    "[5. Deploy](#14th-bullet)<br>\n",
    "- [5.1. Import your test data and apply transformations](#15th-bullet)<br>\n",
    "- [5.2. Obtain Predictions on the test data from your final model](#16th-bullet)<br>\n",
    "- [5.3. Create a Dataframe containing the index of each row and its intended prediction and export it to a csv file](#17th-bullet)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2800040f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1st-bullet\">\n",
    "\n",
    "# 4. Model & Assess (Modelling and Assessment)\n",
    "\n",
    "</a>\n",
    "<img src=\"Images/step4.png\" style=\"height:70px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be5ef49",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<a class=\"anchor\" id=\"2nd-bullet\">\n",
    "\n",
    "## 4.1. Model Selection\n",
    "    \n",
    "</div></a>\n",
    "\n",
    "__`Step 01`__ Import all the needed libraries:\n",
    "\n",
    "- MinMaxScaler from sklearn.preprocessing\n",
    "\n",
    "- LogisticRegression from sklearn.linear_model\n",
    "- KNeighborsClassifier from sklearn.neighbors\n",
    "- DecisionTreeClassifier from sklearn.tree <br><br>\n",
    "\n",
    "- f1_score from sklearn.metrics\n",
    "- roc_curve from sklearn.metrics\n",
    "- precision_recall_curve from sklearn.metrics <br><br>\n",
    "\n",
    "- StratifiedKFold from sklearn.model_selection\n",
    "- train_test_split from sklearn.model_selection\n",
    "- GridSearchCV from sklearn.model_selection\n",
    "- RandomizedSearchCV from sklearn.model_selection \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb01fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "############################################## PREPROCESSING ##############################################\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "################################################# MODELS ##################################################\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "################################################# METRICS #################################################\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "################################### MODEL SELECTION & OPTIMIZATION ########################################\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cedfd48",
   "metadata": {},
   "source": [
    "__`Step 02`__ From the feature selection steps on the previous class, we obtained two different data sets, one called `keep_data` and another named as `all_data`. Import those data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ad5c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_data = pd.read_csv(r'Data/keep_data.csv', index_col=0)\n",
    "X_keep_data = keep_data.iloc[:,:-1]\n",
    "y_keep_data = keep_data.iloc[:,-1]\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X_keep_data, y_keep_data, \n",
    "                                        train_size = 0.9, \n",
    "                                        random_state = 99, \n",
    "                                        stratify = y_keep_data)\n",
    "keep_data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3685ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(r'Data/all_data.csv', index_col=0)\n",
    "X_all_data = all_data.iloc[:,:-1]\n",
    "y_all_data = all_data.iloc[:,-1]\n",
    "X, X_test, y, y_test = train_test_split(X_all_data, y_all_data,           \n",
    "                                        train_size = 0.9, \n",
    "                                        random_state = 99, \n",
    "                                        stratify = y_all_data)\n",
    "all_data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1547827",
   "metadata": {},
   "source": [
    "At this point, we have two data sets to test:\n",
    "- `keep_data`- This dataset is composed by the most important variables defined by the feature selection techniques applied previously. It is composed by: <br><br>\n",
    "    - Mnt, Clothes, NetPurchase, Marital_status, DepVar<br><br>\n",
    "- `all_data` - This dataset is composed by the most important variables defined by the feature selection techniques applied previously, but also with the variables that we are in doubt to use. It is composed by:<br><br>\n",
    "    - Mnt, Clothes, NetPurchase, Marital_status, Rcn, SmallAppliances, Recomendation, DepVar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de1fad0",
   "metadata": {},
   "source": [
    "__NOTE ABOUT PREPROCESSING:__ <br>\n",
    "Concerning the variable `Marital_Status`:\n",
    "- It has misclassifications\n",
    "- It has missing values\n",
    "- Is a categorical variable and we need to convert it to a numerical one\n",
    "\n",
    "Furthermore, the models we are going to apply (except decision trees) are sensible to scaling issues. We need to scale our data accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329f9a7",
   "metadata": {},
   "source": [
    "__`Step 03`__ Create a function called `transform_data` that will receive one or two datasets and make the following changes in the categorical data:\n",
    "\n",
    "In the training data:\n",
    "- Fill missing data in Marital_status with the mode from the training data\n",
    "- Replace 'BigConfusion' to the most frequent value from the training data\n",
    "- Replace 'Together' to 'Married'\n",
    "- Create dummies on your data set, and drop one possible column (for example 'Marital_Status_widow')\n",
    "\n",
    "If you have a second data set (validation or test):\n",
    "- Fill missing data in your second data set in Marital_Status with the mode from the training data\n",
    "- Replace 'BigConfusion' in your second data set to the most frequent value on the training data\n",
    "- Replace 'Together' to 'Married'\n",
    "- Create dummies on your data set, and drop the same column that you dropped on the training data set.\n",
    "\n",
    "__NOTE ABOUT USING DUMMIES WITH pandas.dummies__ <br>\n",
    "When you are creating dummies in your data, it is possible that one class appears on your training data, but not on your second data set (or on the other way around).\n",
    "Take as example:\n",
    "- In your training data, you have a column named 'Animals' with the possible values 'Cat','Dog','Turtle','Goat'. When applying dummies, you are going to create 4 new columns and you should drop one of those to avoid multicollinearity, like for example 'Turtle'.\n",
    "- In your second data set, you have also a column named 'Animals', but this time with the possible values 'Cat','Dog','Turtle'. When applying dummies, you are just going to create 3 new columns and remove 'Turtle'. In this data set, you are not going to have a column named as 'Goat', and this is going to generate an error.\n",
    "\n",
    "One possible way to solve this is to understand wich columns are different from your training data and your second data set. All the columns that are missing are going to be created and filled with zeros. Then, you just need to ensure that the order of the columns is the same in both data sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff4b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(X_train, X_2nd_df = False, X_2nd_df_flag = False):\n",
    "    \n",
    "    ####################################### FILL MISSING DATA #################################################\n",
    "    # Fill missing values (mode in categorical data)\n",
    "    X_train['Marital_Status'].fillna(X_train['Marital_Status'].mode(), inplace = True)\n",
    "    \n",
    "    #################################### CORRECT MISCLASSIFICAIONS ############################################\n",
    "    # Correct misclassifications in the Marital Status in training data\n",
    "    X_train['Marital_Status'] = X_train['Marital_Status'].replace('BigConfusion',X_train['Marital_Status'].mode()[0])\n",
    "    X_train['Marital_Status'] = X_train['Marital_Status'].replace('Together','Married')\n",
    "    \n",
    "    ########################################## CREATE DUMMIES #################################################    \n",
    "    # Create dummies and remove one of the variables (to avoid multicollinearity)\n",
    "    X_train_dummies = pd.get_dummies(X_train)\n",
    "    X_train_dummies.drop('Marital_Status_Widow', axis = 1, inplace = True)\n",
    "   \n",
    "    ############################################ SCALE DATA ###################################################    \n",
    "    scaler = MinMaxScaler().fit(X_train_dummies)\n",
    "    X_train_scaled = scaler.transform(X_train_dummies)\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled , columns = X_train_dummies.columns)\n",
    "    \n",
    "    if X_2nd_df_flag == True:\n",
    "        ####################################### FILL MISSING DATA ############################################# \n",
    "        # Now we fill the missing values in validation data set, using the information available in train\n",
    "        X_2nd_df['Marital_Status'].fillna(X_train['Marital_Status'].mode(), inplace = True)\n",
    "        \n",
    "        #################################### CORRECT MISCLASSIFICAIONS ########################################\n",
    "        # Correct misclassifications in the Marital Status in validation data\n",
    "        X_2nd_df['Marital_Status'] = X_2nd_df['Marital_Status'].replace('BigConfusion',X_train['Marital_Status'].mode()[0])\n",
    "        X_2nd_df['Marital_Status'] = X_2nd_df['Marital_Status'].replace('Together','Married')\n",
    "        \n",
    "        ########################################## CREATE DUMMIES #############################################\n",
    "        X_2nd_df_dummies = pd.get_dummies(X_2nd_df)\n",
    "        X_2nd_df_dummies.drop('Marital_Status_Widow', axis = 1, inplace = True)\n",
    "        \n",
    "        # If we don't have all the values in the validation dataset that we have in the train, that column will not be created\n",
    "        # We should assure that all columns in train are also present in validation\n",
    "        # Get missing columns from the training dataset\n",
    "        missing_cols = set(X_train_dummies.columns ) - set(X_2nd_df_dummies.columns )\n",
    "        # Add a missing column in test set with default value equal to 0\n",
    "        for c in missing_cols:\n",
    "            X_2nd_df_dummies[c] = 0\n",
    "        # Ensure the order of column in the test set is in the same order than in train set\n",
    "        X_2nd_df_dummies = X_2nd_df_dummies[X_train_dummies.columns]\n",
    "        \n",
    "        if 'DepVar' in X_2nd_df_dummies.columns:\n",
    "            X_2nd_df_dummies.drop(['DepVar'], axis=1, inplace=True)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        ############################################ SCALE DATA ###################################################    \n",
    "        X_2nd_df_scaled = scaler.transform(X_2nd_df_dummies) # Scaling with 'scaler' from train data\n",
    "        X_2nd_df_scaled = pd.DataFrame(X_2nd_df_scaled , columns = X_2nd_df_dummies.columns, index = X_2nd_df_dummies.index )\n",
    "        \n",
    "   \n",
    "    if X_2nd_df_flag == False:\n",
    "        return X_train_scaled\n",
    "    else:\n",
    "        return X_train_scaled, X_2nd_df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88bf7cb",
   "metadata": {},
   "source": [
    "__`Step 04`__ Create a function named as `select_best_models` that will receive as arguments your data set and an instance of a model and:\n",
    "- Create an instance of StratifiedKFold with 5 splits, `random_state = 99` and `shuffle = True` named as `skf`.\n",
    "- Define as `X` your independent variables and `y`your target.\n",
    "- Create two empty lists named as `score_train` and `score_val` that will receive the performances of the model for train and for validation.\n",
    "\n",
    "- Inside the loop of the StratifiedKFold:\n",
    "    - Create the dataframes that will correspond to your training data and your validation data at each iteration.\n",
    "    - Call the function defined previously named `transform_data` to do all the needed changes on the data.\n",
    "    - Fit your model to the training data.\n",
    "    - Obtain the predictions of your model in the training data and save those in an object named as `predictions_train`\n",
    "    - Obtain the predictions of your model in the validation data and save those in an object named as `predictions_val`\n",
    "    - Append to the list `score_train` the f1-score obtained in your training data set.\n",
    "    - Append to the list `score_val` the f1-score obtained in your validation data set.\n",
    "\n",
    "- After all the iterations on the StratifiedKFold:\n",
    "    - Calculate the mean and the standard deviation of the performance of the models in the training data.\n",
    "    - Calculate the mean and the standard deviation of the performance of the models in the validation data.\n",
    "\n",
    "- Return those results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce6da061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_models(data, model):\n",
    "    skf = StratifiedKFold(n_splits = 5, random_state = 99, shuffle = True)\n",
    "    X = data.drop('DepVar', axis = 1)\n",
    "    y = data['DepVar'].copy()\n",
    "    score_train, score_val = [],[]\n",
    "        \n",
    "    # perform the cross-validation    \n",
    "    for train_index, val_index in skf.split(X,y):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        # Change categorical data - call function \"transform_data\"\n",
    "        X_train, X_val = transform_data(X_train, X_val, X_2nd_df_flag = True)\n",
    "        \n",
    "        # Apply model\n",
    "        model.fit(X_train, y_train) #fit vai estabelecer as relações entre o x e o y para que quando passarmos o valor de x, ele conseguir prever o valor de y\n",
    "        predictions_train = model.predict(X_train) #com base no que foi feito no fit, vamos pegar na variavel x e indicar o valor da variavel em y. Mas neste caso estamos a usar os mesmos dados que usamos em fit. É previsivel que haja um bom acerto.\n",
    "        predictions_val = model.predict(X_val)\n",
    "        score_train.append(f1_score(y_train, predictions_train))\n",
    "        score_val.append(f1_score(y_val, predictions_val))\n",
    "\n",
    "    avg_train = round(np.mean(score_train),3)\n",
    "    avg_val = round(np.mean(score_val),3)\n",
    "    std_train = round(np.std(score_train),2)\n",
    "    std_val = round(np.std(score_val),2)\n",
    "\n",
    "    return avg_train, std_train, avg_val, std_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb62f9ba",
   "metadata": {},
   "source": [
    "__`Step 05`__ Create a function called `show_results` that will receive as arguments:\n",
    "- A dataframe to be filled with the results\n",
    "- Your data set\n",
    "- One or more instances of models.\n",
    "\n",
    "Inside this function, you are going to create a loop where for each model you receive as argument:\n",
    "- you are going to obtain the average and the standard deviation of the performance in train and in validation by calling the function `select_best models`, passing as arguments your data and the instance of your model.\n",
    "- Fill the dataframe with those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b48cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(df, data, *args):\n",
    "    count = 0\n",
    "    # for each instance of model passed as argument\n",
    "    for arg in args:\n",
    "        avg_train, std_train, avg_val, std_val = select_best_models(data, arg)\n",
    "        # store the results in the right row\n",
    "        df.iloc[count] = str(avg_train) + '+/-' + str(std_train), str(avg_val) + '+/-' + str(std_val)\n",
    "        count+=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f610eae6",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"3rd-bullet\">\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### 4.1.1. Compare different algorithms and select the most promising ones  \n",
    "    \n",
    "</div></a>\n",
    "\n",
    "\n",
    "__`Step 06`__ The first thing we are going to do is to compare the performance of different algorithms with the default parameters. The only exceptions on the hyperparameters are:\n",
    "- The decision tree will be tested with max_depth = 3 <br>\n",
    "        - __*Why?*__ Decision Trees by default are going to grow until full depth on the training data set. This will lead to situations of overfitting. <br>\n",
    "         \n",
    "- __`Step 6.1.`__ Create an instance of a LogisticRegression named as `model_LR`\n",
    "- __`Step 6.2.`__ Create an instance of a KNeighborsClassifier named as `model_KNN`\n",
    "- __`Step 6.3.`__ Create an instance of a DecisionTreeClassifier named as `model_DT`. Define `max_depth = 3` and `random_state = 99`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9987ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = LogisticRegression()\n",
    "model_KNN = KNeighborsClassifier()\n",
    "model_DT = DecisionTreeClassifier(max_depth = 3, random_state = 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef63c86",
   "metadata": {},
   "source": [
    "__`Step 07`__ Create a Dataframe with the columns `['Train', 'Validation]` and the index `['Logistic Regression','KNN','DT']` named as `df_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f8f7676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame(columns = ['Train','Validation'], index = ['Logistic Regression','KNN','DT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4056fcb",
   "metadata": {},
   "source": [
    "__`Step 08`__ Call the function `show_results` and pass as arguments:\n",
    "- The dataframe `df_all` - This will store the results from the different models;\n",
    "- The data set `all_data`- This is the data we are going to use to train and validate the different models;\n",
    "- The models `model_LR`, `model_KNN` and `model_DT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c34e4acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.228+/-0.03</td>\n",
       "      <td>0.213+/-0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.412+/-0.03</td>\n",
       "      <td>0.296+/-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.359+/-0.05</td>\n",
       "      <td>0.313+/-0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Train    Validation\n",
       "Logistic Regression  0.228+/-0.03  0.213+/-0.06\n",
       "KNN                  0.412+/-0.03  0.296+/-0.05\n",
       "DT                   0.359+/-0.05  0.313+/-0.09"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_results(df_all, all_data, model_LR, model_KNN, model_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ebbd29",
   "metadata": {},
   "source": [
    "__`Step 09`__ Similarly to what you have done on Step 07, now create a Dataframe called `df_keep`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2154bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keep = pd.DataFrame(columns = ['Train','Validation'], index = ['Logistic Regression','KNN','DT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a813103",
   "metadata": {},
   "source": [
    "__`Step 10`__ Call the function `show_results` and pass as arguments:\n",
    "- The dataframe `df_keep` - This will store the results from the different models;\n",
    "- The data set `keep_data`- This is the data we are going to use to train and validate the different models;\n",
    "- The models `model_LR`, `model_KNN` and `model_DT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34b89924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.225+/-0.02</td>\n",
       "      <td>0.222+/-0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.434+/-0.04</td>\n",
       "      <td>0.3+/-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.381+/-0.02</td>\n",
       "      <td>0.351+/-0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Train    Validation\n",
       "Logistic Regression  0.225+/-0.02  0.222+/-0.08\n",
       "KNN                  0.434+/-0.04    0.3+/-0.03\n",
       "DT                   0.381+/-0.02  0.351+/-0.03"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_results(df_keep, keep_data, model_LR, model_KNN, model_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec1e12f",
   "metadata": {},
   "source": [
    "__CONCLUSION:__\n",
    "- By comparing the results when using the dataset `all_data` and `keep_data`, it seems that the last one leads to better results on validation data set, except on the KNN. <br><br>\n",
    "- The __best models__ in validation are, in descending order:\n",
    "    - Decision Tree, with an f1-score of 0.351\n",
    "    - K-Nearest Neighbors, with an f1-score of 0.3\n",
    "    - Logistic Regression, with an f1-score of 0.222\n",
    "    <br><br>\n",
    "    \n",
    "- Considering __overfitting__:\n",
    "    - K-Nearest Neighbors is the model with more overfitting, with a difference between train and validation of around 0.134;\n",
    "    - Decision Tree has a difference between train and validation of around 0.03;\n",
    "    - Logistic Regression is the model that suffers less from overfitting, with a difference between train and validation of around 0.003;\n",
    "\n",
    "    \n",
    "Decision Trees seems to be the most promising model, followed by K-Nearest Neighbors.\n",
    "    \n",
    "Usually in this phase, after testing several algorithms, we choose the most promising ones and try to optimize them, in order to select the winner model. <br>\n",
    "\n",
    "As so, we are going to reject at this point the Logistic Regression and try to improve the remaining ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89421085",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<a class=\"anchor\" id=\"4th-bullet\">\n",
    "\n",
    "## 4.2. Model Optimization\n",
    "    \n",
    "</div></a>\n",
    "\n",
    "After selecting the best algorithm (set of algorithms), you can try to optimize the performance of your model by fiddling with the algorithms' hyper-parameters and select the options that result on the best overall performance.\n",
    "\n",
    "Possible ways of doing this can be through:\n",
    "1. Manual optimization\n",
    "2. [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "3. [RandomSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b73e9c",
   "metadata": {},
   "source": [
    "We are going to compare the f1-score for different algorithms with different hyperparameters in train and validation dataset. We can use a pointplot from seaborn to plot the results. <br>\n",
    "\n",
    "__`Step 11`__ Create a function called `point_plot` that receives as arguments: <br>\n",
    "- The results from the training data (`train`)<br>\n",
    "- The results from the validation data (`validation`)<br>\n",
    "- A list of the different values tested as hyperparameters (`values_try`). <br> <br>\n",
    "    \n",
    "Inside the function, we are going to create two pointplots (`sns.pointplot`):<br>\n",
    "- One where the x axis will be equal to the `values_try`, the y will represent the training results, the `color = teal` and the `label = Train`.<br>\n",
    "- One where the x axis will be equal to the `values_try`, the y will represent the validation results, the `color = goldenrod` and the `label = Validation`.<br>\n",
    "- Call the command plt.legend() to add a legend to the plot.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dc0a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_plot(train, validation, values_try):\n",
    "    sns.pointplot(x=values_try, y=train, color = 'teal', label = 'Train')\n",
    "    sns.pointplot(x=values_try, y=validation, color = 'goldenrod', label = 'Validation')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71030d1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<a class=\"anchor\" id=\"5th-bullet\">\n",
    "\n",
    "### 4.2.1. K-Nearest Neighbor\n",
    "    \n",
    "</a>\n",
    "    \n",
    "<b>class sklearn.neighbors.KNeighborsClassifier</b>(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b3af4f",
   "metadata": {},
   "source": [
    "In K-Nearest Neighbor, the hyperparameter `n_neighbors` define the number of neighbors to take into consideration. \n",
    "Having a small value of neighbors in k-nearest neighbors (KNN) algorithm typically leads to overfitting and using a large value of k in KNN tends to result in smoother decision boundaries and can lead to underfitting.\n",
    "\n",
    "__`Step 12`__ Create a function called `get_models_knn` that receives as parameters the data set you want to use and a list of values of different number of neighbors. <br>\n",
    "Inside this function you will:\n",
    "- create an empty dictionary called `models` that will receive several instances of models.\n",
    "- create two empty lists: `results_train` and `results_val`\n",
    "\n",
    "For each value of neighbors:\n",
    "- Create an instance of a KNeighborsClassifier with `n_neighbors = value`. This will be an element on the dictionary, where the key is the name of the model and the value is the instance itself.\n",
    "\n",
    "For each entry / instance of model you have in your dictionary:\n",
    "- run the function select_best_models and get the average value of the performance for train, validation, and the name of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30dc6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_knn(data, values):\n",
    "    models = dict()\n",
    "    results_train, results_val = [],[]\n",
    "    \n",
    "    # create the instances of each model with different values\n",
    "    for value in values:\n",
    "        models['neighbors_' + str(value)] = KNeighborsClassifier(n_neighbors = value)\n",
    "        \n",
    "    for i, model in models.items():\n",
    "        avg_train, std_train, avg_val, std_val = select_best_models(data, model)\n",
    "        results_train.append(avg_train)\n",
    "        results_val.append(avg_val)\n",
    "\n",
    "    print(results_train)\n",
    "    print(results_val)\n",
    "        \n",
    "        \n",
    "    return results_train, results_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93de10e0",
   "metadata": {},
   "source": [
    "__`Step 13`__ In this step:\n",
    "- Define a list of number of neighbors to test, namely [1,3,5,7,9,11]. \n",
    "- Call the function previously defined `get_models_knn` passing as arguments your data set and the list of neighbors.\n",
    "- Call the function `point_plot`passing as arguments the results of the training data set, the results of the validation data set and the values of neighbors that you try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d64d5a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(1.0), np.float64(0.54), np.float64(0.434), np.float64(0.348), np.float64(0.289), np.float64(0.228)]\n",
      "[np.float64(0.342), np.float64(0.354), np.float64(0.3), np.float64(0.23), np.float64(0.257), np.float64(0.154)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUrJJREFUeJzt3Xl4VNX9P/D3nZlkJvu+TTJJCAmEPUBCEkAWBREpQlstP2tlEawiWpXaKhXFpRVb1LqA2CJCtV+rYiu0giAiyBYgAcK+BQLZ932dzMz9/REYs2cmmZk7k7xfz5OnPXfOvfNJQOadc889RxBFUQQRERGRRGRSF0BERET9G8MIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYXUBZjCYDAgLy8PHh4eEARB6nKIiIjIBKIoorq6Gmq1GjJZ5+MfDhFG8vLyoNFopC6DiIiIeiA7OxthYWGdvu4QYcTDwwNA8zfj6ekpcTVERERkiqqqKmg0GuPneGccIozcujXj6enJMEJERORguptiwQmsREREJCmGESIiIpIUwwgRERFJyiHmjBARUd8giiJ0Oh30er3UpZAFyOVyKBSKXi+7wTBCREQ2odVqkZ+fj7q6OqlLIQtydXVFSEgInJ2de3wNhhEiIrI6g8GAzMxMyOVyqNVqODs7cxFLByeKIrRaLYqLi5GZmYmYmJguFzbrCsMIERFZnVarhcFggEajgaurq9TlkIW4uLjAyckJN27cgFarhUql6tF1GEZ6SRRFHM3NxbaLF1He0AAflQpzYmORGBrK1E9E1EZPf3Mm+2WJP1OGkV44V1SEhdu2IS0vr9Xx1w8dQrxajc1z5mBYYKBE1RERETkGs+PM/v37MXv2bKjVagiCgK1bt3Z7zr59+zBmzBgolUpER0dj8+bNPSjVvpwrKsLETZvaBZFb0vLyMHHTJpwrKrJxZUREfZMoijiSk4MV332HR7/+Giu++w5HcnIgiqLUpVEvmR1GamtrMWrUKKxbt86k/pmZmZg1axamTp2K9PR0PPXUU1iyZAl27dpldrH2QhRFLNy2DRUNDV32q2howKJt2/gfChFRL50rKsK4Dz9E8saNeP3QIfzt+HG8fugQkjduxLgPP3SoX/wiIyPx9ttvS12GXTH7Ns3MmTMxc+ZMk/t/8MEHGDBgAN58800AwJAhQ3Dw4EH89a9/xYwZM8x9e7twNDe30xGRtlLz8nAsNxeJXexWSEREnbs1Et3ZL4C3RqIPLlpk0Vvj3c37W7VqFV566SWzr5uamgo3N7ceVtU3WX0mUUpKCqZNm9bq2IwZM5CSktLpOY2Njaiqqmr1ZU+2XbxoVv+tZvYnIqJmUo5E5+fnG7/efvtteHp6tjr2zDPPtKpTp9OZdN2AgAA+UdSG1SewFhQUICgoqNWxoKAgVFVVob6+Hi4uLu3OWb16NV5++WVrl9Zj5d38R9Hb/kREfd3Ejz5Cjgm/aDbqdCiorTXpmql5eVC/+SaUiq4/2sI8PXHwoYe6vV5wcLDx/3t5eUEQBOOxffv2YerUqdixYwdWrlyJM2fO4Ntvv4VGo8Hy5ctx5MgR1NbWYsiQIVi9enWrX8ojIyPx1FNP4amnngLQPAKzYcMGbN++Hbt27UJoaCjefPNN3HPPPSZ9332BXT5Ns2LFCixfvtzYrqqqgkajkbCi1nzMfI7a3P5ERH1dTlUVblRWWvy6pgYXS3nuuefwxhtvICoqCj4+PsjOzsbdd9+NP/3pT1Aqlfj4448xe/ZsXLp0CeHh4Z1e5+WXX8Zf/vIXrFmzBu+99x4eeOAB3LhxA76+vjb8bqRj9ds0wcHBKCwsbHWssLAQnp6eHY6KAIBSqYSnp2erL3syJzbWrP5zzexPRESO4ZVXXsH06dMxcOBA+Pr6YtSoUXjkkUcwfPhwxMTE4NVXX8XAgQPx3//+t8vrLFy4EPfffz+io6Px2muvoaamBseOHbPRdyE9q4+MJCcnY8eOHa2O7d69G8nJydZ+a6tJDA1FvFpt0iTWBLUa40JDbVAVEZHjCDPxl8zyhgZUNTaafF1PpbLb0WhT39sU8fHxrdo1NTV46aWXsH37duTn50On06G+vh5ZWVldXmfkyJHG/+/m5gZPT08UOdATQr1ldhipqalBRkaGsZ2ZmYn09HT4+voiPDwcK1asQG5uLj7++GMAwKOPPoq1a9fi97//PR566CF8//33+OKLL7B9+3bLfRc2JggCNs+Z0+XsbgDwVqmwac4crsRKRNSGKXM2AOBITg6SN240+brf/upXNn16se1TMc888wx2796NN954A9HR0XBxccG9994LrVbb5XWcnJxatQVBgMFgsHi99srs2zRpaWkYPXo0Ro8eDQBYvnw5Ro8ejRdffBFA8+zjlglwwIAB2L59O3bv3o1Ro0bhzTffxIcffuiwj/XeMiwwEAcXLUK8Wt1pn6eTkrgCKxFRL9waiTaFPYxEHzp0CAsXLsRPf/pTjBgxAsHBwbh+/bqkNTkCs0dGpkyZ0uWjUx2trjplyhScPHnS3Leye8MCA3FsyRIcy83F1osXcbqwEDtajBp9dvYsVk6aBBlHRoiIesTRRqJjYmLwn//8B7Nnz4YgCHjhhRf61QhHT3HHol4SBAGJYWFYPW0avv7lLzG8xUjIhZIS7GwRToiIyHzdjUQnqNUWX/Csp9566y34+Phg/PjxmD17NmbMmIExY8ZIXZbdE0QHWKu8qqoKXl5eqKystLsna9ranJ6ORdu2GdtTIyPx/YIFElZERCS9hoYGZGZmYsCAAT3eZl4UReNI9K1d0ufGxmIcd0mXVFd/tqZ+ftvlOiOO7P7hw/GHPXuQX1MDANh7/TqO5+VhrIn3PImIqGO3RqK5vUbfw9s0FqZUKPCbxMRWx97sYul7IiKi/o5hxAoeGTsWbi0e0/ri3DncqKiQriAiIiI7xjBiBT4uLlh889FnANCLIt45elTCioiIiOwXw4iVPJWU1OqR3g0nTnS76yQREVF/xDBiJQN8fHDv0KHGdo1Wiw3Hj0tYERERkX1iGLGiZ9rsv/PO0aPQ6vUSVUNERGSfGEasKCE0FJMiIozt3OpqfH72rIQVERER2R+GEStrOzryRkpKl8vpExFRx0RRRH3JSZSk/wWFx55HSfpfUF9y0q7/TZ0yZQqeeuopYzsyMhJvv/12l+cIgoCtW7f2+r0tdR1b4KJnVjZr0CAM9vPDpdJSAMDpwkJ8d+0apg8cKHFlRESOo7HiMgqP/A6NZadbHS8/vx5K35EISloDpfcgi77n7Nmz0dTUhJ07d7Z77cCBA5g0aRJOnTqFkSNHmnzN1NTUdjv99tZLL72ErVu3Ij09vdXx/Px8+Pj4WPS9rIUjI1YmEwQsbzM6wkXQiIhM11hxGTm772sXRIyvl51ufr3iskXfd/Hixdi9ezdycnLavbZp0ybEx8ebFUQAICAgAK6urpYqsUvBwcFQKpU2ea/eYhixgQdHjkRAi798u65exenCQgkrIiJyDKIoovDI72Boquqyn6GpCoVHfmfRWzY/+clPEBAQ0G43+pqaGmzZsgVz587F/fffj9DQULi6umLEiBH417/+1eU1296muXLlCiZNmgSVSoWhQ4di9+7d7c559tlnMWjQILi6uiIqKgovvPACmpqaAACbN2/Gyy+/jFOnTkEQhOZdjm/W2/Y2zZkzZ3D77bfDxcUFfn5++PWvf42am1uXAMDChQsxd+5cvPHGGwgJCYGfnx+WLVtmfC9r4m0aG3BxcsLj48Zh1b59xmNvpaRg89y5ktVERCSl7N33QVeX320/Ua+FvqHYpGs2lp1G5leJEOTOXfZTuIZAM31Lt9dTKBSYP38+Nm/ejOeff964Gd+WLVug1+vxq1/9Clu2bMGzzz4LT09PbN++HQ8++CAGDhyIcePGdXt9g8GAn/3sZwgKCsLRo0dRWVnZan7JLR4eHti8eTPUajXOnDmDhx9+GB4eHvj973+PefPm4ezZs9i5cye+++47AICXl1e7a9TW1mLGjBlITk5GamoqioqKsGTJEjz++OOtwtbevXsREhKCvXv3IiMjA/PmzUNcXBwefvjhbr+f3mAYsZHHEhKw+uBBNOh0AIBPz5zBn26/HaF2vgsxEZE16OryoavNtfh1TQ0upnrooYewZs0a/PDDD5gyZQqA5ls0P//5zxEREYFnnnnG2PeJJ57Arl278MUXX5gURr777jtcvHgRu3btgvrmZqqvvfYaZs6c2arfypUrjf8/MjISzzzzDD777DP8/ve/h4uLC9zd3aFQKBAcHNzpe3366adoaGjAxx9/bJyzsnbtWsyePRt//vOfERQUBADw8fHB2rVrIZfLERsbi1mzZmHPnj1WDyO8TWMj/q6uWBQXZ2w3GQx479gx6QoiIqJuxcbGYvz48fjoo48AABkZGThw4AAWL14MvV6PV199FSNGjICvry/c3d2xa9cuZGVlmXTtCxcuQKPRGIMIACS3mWMIAJ9//jkmTJiA4OBguLu7Y+XKlSa/R8v3GjVqVKvJsxMmTIDBYMClS5eMx4YNGwa5XG5sh4SEoKioyKz36gmGERt6OikJQov2B2lpqG5slKweIiKpKFxDoHAL7fZLcHI367qCk3v313UNMeuaixcvxr///W9UV1dj06ZNGDhwICZPnow1a9bgnXfewbPPPou9e/ciPT0dM2bMgFarNev6XUlJScEDDzyAu+++G19//TVOnjyJ559/3qLv0ZJTi01egeZ5JwaDwSrv1RJv09hQjJ8f5sTGYuvFiwCAysZGfHTyJJ5MSpK4MiIi2zJlzgYA1JecRM63PzP5umFTP4bKf3T3Hc3wi1/8Ak8++SQ+/fRTfPzxx1i6dCkEQcChQ4cwZ84c/OpXvwLQPAfk8uXLGNpiK5CuDBkyBNnZ2cjPz0dISHNAOnLkSKs+hw8fRkREBJ5//nnjsRs3brTq4+zsDH03q3sPGTIEmzdvRm1trXF05NChQ5DJZBg8eLBJ9VoTR0ZsrO0iaH89cgQ6G6ROIiJHpPKLg9LXtMdnlb4jofSLs3gN7u7umDdvHlasWIH8/HwsXLgQABATE4Pdu3fj8OHDuHDhAh555BEUmvGk5LRp0zBo0CAsWLAAp06dwoEDB1qFjlvvkZWVhc8++wxXr17Fu+++i6+++qpVn8jISGRmZiI9PR0lJSVo7GDE/YEHHoBKpcKCBQtw9uxZ7N27F0888QQefPBB43wRKTGM2Nh4jQZJYWHG9o3KSvz7/HkJKyIisl+CICAoaQ1kTl1P9pc5eSIoaY3xiRdLW7x4McrLyzFjxgzjHI+VK1dizJgxmDFjBqZMmYLg4GDMNeMpSZlMhq+++gr19fUYN24clixZgj/96U+t+txzzz14+umn8fjjjyMuLg6HDx/GCy+80KrPz3/+c9x1112YOnUqAgICOny82NXVFbt27UJZWRkSEhJw77334o477sDatWvN/2FYgSDa8zq6N1VVVcHLywuVlZXw7ANPn/z7/Hncu+XHIcqxISFIffhhq/1HREQktYaGBmRmZmLAgAFQqVRmn9/ZCqwArLYCK5mmqz9bUz+/OWdEAnNjYxHl44Nr5eUAgOP5+dh/4wYmR0ZKWxgRkZ1Seg+CZsZWNJamoyZnN/TaSsidveAeNh1Kvzj+MufgGEYkIJfJ8HRSEp745hvjsTdSUhhGiIi6IAgCVP6jLT5BlaTHOSMSWRQXB58Ww1lfX76MC8WWXayHiIjIETCMSMTN2RmPJSS0OvbXNo90ERER9QcMIxJ6fNw4OLdY6e7jU6dQ2GLTIiIiov6AYURCwe7ueLDF9tONej3WpaZKWBERkXU5wAOcZCZL/JkyjEhseZtF0NalpqLOBts1ExHZ0q1lxuvq6iSuhCzt1p9p26XkzcGnaSQ2NCAAd8fEYMeVKwCAsvp6bE5PbzefhIjIkcnlcnh7exs3XXN1deXjuA5OFEXU1dWhqKgI3t7erTbYMxfDiB14JjnZGEYA4K2UFDwydizkMg5cEVHfcWuLe1vsAku24+3tbfyz7SmGETswJTISY0JCcCI/HwBwtbwc/710CT8dMkTiyoiILEcQBISEhCAwMBBNvB3dJzg5OfVqROQWhhE7IAgCnklOxi//8x/jsTdSUhhGiKhPksvlFvkAo76D9wHsxL1DhyLcy8vYPpydjcPZ2RJWREREZBsMI3bCSS7HU4mJrY69mZIiUTVERES2wzBiR5aMGQMvpdLY/urCBWSUlUlYERERkfUxjNgRD6USvx471tgWAfyVoyNERNTHMYzYmd8kJkLR4pHeTenpKOUiQURE1IcxjNiZME9P3D98uLFdr9NhfVqahBURERFZF8OIHfptmyXi3zt2DA06nUTVEBERWRfDiB0aFRyM6VFRxnZRbS3+efq0hBURERFZD8OInXpm/PhW7TdTUmDgbpdERNQHMYzYqelRURgRGGhsXywpabV/DRERUV/BMGKnBEFoN3eEi6AREVFfxDBix+4fMQJqDw9je9/160jLy5OwIiIiIstjGLFjznI5fjNuXKtjHB0hIqK+hmHEzj0SHw93Z2dje8u5c7heUSFdQURERBbGMGLnvFUqLBk92tjWiyLeOXJEwoqIiIgsi2HEATyZlASZIBjbH548iYqGBgkrIiIishyGEQcQ6e2N+4YONbZrtFr8/fhxCSsiIiKyHIYRB9F2EbR3jh6FVq+XqBoiIiLLYRhxEPFqNSZHRBjbedXV+OzsWQkrIiIisgyGEQfSdnTkjcOHIXKJeCIicnAMIw7k7pgYxPr7G9tnioqw+9o1CSsiIiLqPYYRByITBCxPSmp17I3DhyWqhoiIyDIYRhzMg6NGIdDNzdjefe0aThcWSlgRERFR7zCMOBiVQoHHExJaHeMS8URE5MgYRhzQ0oQEuCgUxvanZ84gp6pKwoqIiIh6jmHEAfm7umJRXJyxrTMY8N7Ro9IVRERE1AsMIw7q6eRkCC3aHxw/jqrGRsnqISIi6imGEQcV7euLnw4ZYmxXNTZi44kTElZERETUMwwjDuy3ycmt2m8fPQqdwSBRNURERD3DMOLAxms0SA4LM7azKivx5fnzElZERERkPoYRB9d2ifg1XCKeiIgcDMOIg5szeDAG+vgY2yfy8/HDjRsSVkRERGQehhEHJ5fJsLzN3BEuEU9ERI6EYaQPWBgXBz8XF2N7+5UruFBcLGFFREREpmMY6QNcnZywND6+1bG3uEQ8ERE5CIaRPuLxcePgLJcb2x+fPo2CmhoJKyIiIjJNj8LIunXrEBkZCZVKhcTERBw7dqzL/m+//TYGDx4MFxcXaDQaPP3002hoaOhRwdSxIHd3zB850tjW6vVY182fCxERkT0wO4x8/vnnWL58OVatWoUTJ05g1KhRmDFjBoqKijrs/+mnn+K5557DqlWrcOHCBWzcuBGff/45/vCHP/S6eGqt7UTW99PSUKvVSlQNERGRacwOI2+99RYefvhhLFq0CEOHDsUHH3wAV1dXfPTRRx32P3z4MCZMmIBf/vKXiIyMxJ133on777+/29EUMt+QgAD8ZNAgY7usvh6b09OlK4iIiMgEZoURrVaL48ePY9q0aT9eQCbDtGnTkNLJhMnx48fj+PHjxvBx7do17NixA3fffXen79PY2IiqqqpWX2SaZ9qMjrx15Aj0XCKeiIjsmFlhpKSkBHq9HkFBQa2OBwUFoaCgoMNzfvnLX+KVV17BxIkT4eTkhIEDB2LKlCld3qZZvXo1vLy8jF8ajcacMvu1SRERGBsSYmxfKy/HtkuXJKyIiIioa1Z/mmbfvn147bXX8P777+PEiRP4z3/+g+3bt+PVV1/t9JwVK1agsrLS+JWdnW3tMvsMQRDaLRHPRdCIiMieKczp7O/vD7lcjsLCwlbHCwsLERwc3OE5L7zwAh588EEsWbIEADBixAjU1tbi17/+NZ5//nnIZO3zkFKphFKpNKc0auHeoUPx7HffIauyEgCQkpODw9nZGM8RJiIiskNmjYw4Oztj7Nix2LNnj/GYwWDAnj17kNxmrsItdXV17QKH/OZ6GNzQzToUMhmeTkpqdYyjI0REZK/Mvk2zfPlybNiwAf/4xz9w4cIFLF26FLW1tVi0aBEAYP78+VixYoWx/+zZs7F+/Xp89tlnyMzMxO7du/HCCy9g9uzZxlBClrd49Gh4tRhd2nrxIq6UlkpYERERUcfMuk0DAPPmzUNxcTFefPFFFBQUIC4uDjt37jROas3Kymo1ErJy5UoIgoCVK1ciNzcXAQEBmD17Nv70pz9Z7rugdjyUSjwaH48/HzoEABAB/PXIEbw/a5a0hREREbUhiA5wr6SqqgpeXl6orKyEp6en1OU4jNyqKkS+8w50Nx/tdVEokPX00/B3dZW4MiIi6g9M/fzm3jR9WKinJ345YoSxXa/TYX1qqoQVERERtccw0sf9ts3E4veOHUODTidRNURERO0xjPRxI4OCcOfAgcZ2cV0dPjl1SsKKiIiIWmMY6QfaLhH/ZkoKDPY/VYiIiPoJhpF+YFpUFEa2WML/Umkptl++LGFFREREP2IY6QcEQWg3d+TNTjY2JCIisjWGkX7i/w0fDrWHh7H9w40bSM3NlbAiIiKiZgwj/YSzXI4nExNbHePoCBER2QOGkX7k12PHwt3Z2djecv48rldUSFcQERERGEb6FW+VCg+PGWNsG0QRbx85ImFFREREDCP9zpOJiZALgrH94YkTKK+vl7AiIiLq7xhG+pkIb2/8YtgwY7u2qQl/P35cwoqIiKi/Yxjph9o+5vvO0aPQ6vUSVUNERP0dw0g/NFatxpTISGM7v6YG/zpzRrqCiIioX2MY6afaLhH/RkoKRC4RT0REEmAY6admxsRgiL+/sX22qAjfXr0qYUVERNRfMYz0U7IOloh/g4ugERGRBBhG+rEHRo5EkJubsf3dtWs4VVAgYUVERNQfMYz0YyqFAo+PG9fqGJeIJyIiW2MY6eeWxsfDRaEwtv919ixyqqokrIiIiPobhpF+zs/VFQ+NHm1s6wwGvHv0qIQVERFRf8MwQng6KQlCi/bfjh9HVWOjZPUQEVH/wjBCGOjri58NGWJsVzU24sMTJySsiIiI+hOGEQIAPDN+fKv2O0ePoolLxBMRkQ0wjBAAICksDOM1GmM7q7ISX54/L2FFRETUXzCMkBGXiCciIikwjJDRPYMHI9rX19g+kZ+PfdevS1cQERH1CwwjZCSXybA8KanVMS4RT0RE1sYwQq0siIuDn4uLsb3jyhWcLy6WsCIiIurrGEaoFVcnJyxLSGh17C2OjhARkRUxjFA7y8aNg1IuN7Y/OX0aBTU1ElZERER9GcMItRPo5ob5o0YZ21q9HmuPHZOwIiIi6ssYRqhDy9s85vt+aipqtVqJqiEior6MYYQ6FOvvj9mDBhnb5Q0N2JSeLl1BRETUZzGMUKfaLhH/1yNHoDcYJKqGiIj6KoYR6tRt4eFIUKuN7Wvl5dh68aKEFRERUV/EMEKdEgQBv20zd2TN4cNcIp6IiCyKYYS69POhQxHh5WVsH83NxeHsbAkrIiKivoZhhLqkkMnwNJeIJyIiK2IYoW49NHo0vFUqY3vbxYu4XFoqYUVERNSXMIxQtzyUSjw6dqyxLQL4K0dHiIjIQhhGyCRPJCbCSfbjX5fNp06huLZWwoqIiKivYBghk6g9PPDAyJHGdoNOh/VpaRJWREREfQXDCJlseZuJrGuPHUN9U5NE1RARUV/BMEImGxEUhBkDBxrbxXV1+OT0aQkrIiKivoBhhMzSdon4N1NSYOAiaERE1AsMI2SWOwYMwKigIGP7cmkpvr58WcKKiIjI0TGMkFkEQWg3OvLG4cMSVUNERH0BwwiZbd6wYQj18DC2D2Rl4VhuroQVERGRI2MYIbM5yeV4MjGx1bE3uQgaERH1EMMI9civx46Fh7Ozsf3l+fPILC+XsCIiInJUDCPUI14qFR4eM8bYNogi3j5yRMKKiIjIUTGMUI89mZQEuSAY2xtPnkRZfb2EFRERkSNiGKEeC/fywrzhw43t2qYm/I1LxBMRkZkYRqhXfpuc3Kr93rFjaNTpJKqGiIgcEcMI9cqYkBBMjYw0tvNravCvs2elK4iIiBwOwwj1WkeLoIlcIp6IiEzEMEK9dld0NIYGBBjb54qLsevqVQkrIiIiR8IwQr0mE4R2c0e4RDwREZmKYYQs4oERIxDk5mZs78nMRHpBgYQVERGRo2AYIYtQKhT4DZeIJyKiHmAYIYt5ND4erk5OxvZnZ88iu7JSwoqIiMgRMIyQxfi6uOChuDhjW2cw4N2jR6UriIiIHALDCFnUU0lJkLVYIv5vx4+jsqFBwoqIiMjeMYyQRQ309cXPhgwxtqu1Wnx44oSEFRERkb1jGCGLe6bNY75vHz2KJr1eomqIiMjeMYyQxSWGhWFieLixnVNVhS3nz0tYERER2TOGEbKKtqMjXCKeiIg606Mwsm7dOkRGRkKlUiExMRHHjh3rsn9FRQWWLVuGkJAQKJVKDBo0CDt27OhRweQYZg8ejBhfX2P7ZEEB9l6/Ll1BRERkt8wOI59//jmWL1+OVatW4cSJExg1ahRmzJiBoqKiDvtrtVpMnz4d169fx5dffolLly5hw4YNCA0N7XXxZL9kgoDlXCKeiIhMIIhmjp0nJiYiISEBa9euBQAYDAZoNBo88cQTeO6559r1/+CDD7BmzRpcvHgRTi0WxDJHVVUVvLy8UFlZCU9Pzx5dg2yvrqkJEW+/jZK6OuOxM0uXYnhgoIRVERGRrZj6+W3WyIhWq8Xx48cxbdq0Hy8gk2HatGlI6WTp7//+979ITk7GsmXLEBQUhOHDh+O1116DvounKxobG1FVVdXqixyPq5MTliUktDr2FpeIJyKiNswKIyUlJdDr9QgKCmp1PCgoCAWdbIp27do1fPnll9Dr9dixYwdeeOEFvPnmm/jjH//Y6fusXr0aXl5exi+NRmNOmWRHHktIgEqhMLb/78wZ5FdXS1gRERHZG6s/TWMwGBAYGIi///3vGDt2LObNm4fnn38eH3zwQafnrFixApWVlcav7Oxsa5dJVhLo5oYFo0YZ21q9Hmu7mfBMRET9i1lhxN/fH3K5HIWFha2OFxYWIjg4uMNzQkJCMGjQIMjlcuOxIUOGoKCgAFqttsNzlEolPD09W32R43o6KalVe31aGmo6+bMnIqL+x6ww4uzsjLFjx2LPnj3GYwaDAXv27EFymycnbpkwYQIyMjJgMBiMxy5fvoyQkBA4Ozv3sGxyJIP9/XHP4MHGdnlDAzadPClhRUREZE/Mvk2zfPlybNiwAf/4xz9w4cIFLF26FLW1tVi0aBEAYP78+VixYoWx/9KlS1FWVoYnn3wSly9fxvbt2/Haa69h2bJllvsuyO61XQTtr0eOQNcioBIRUf+l6L5La/PmzUNxcTFefPFFFBQUIC4uDjt37jROas3KyoJM9mPG0Wg02LVrF55++mmMHDkSoaGhePLJJ/Hss89a7rsguzcxPBzjQkNxLDcXAJBZUYGvLlzAfcOGSVwZERFJzex1RqTAdUb6hi3nzuEXX35pbI8LDcWRxYshCIKEVRERkbVYZZ0Rot746ZAhGODtbWwfy83FIT4pRUTU7zGMkM0oZDI81ebJGi4RT0REDCNkUw+NHg1vlcrY/u+lS7hUUiJhRUREJDWGEbIpd2dnLI2PN7ZFND9ZQ0RE/RfDCNncE+PGwanFE1f/OHUKxbW1ElZERERSYhghmwvx8MCvRo40tht0OryfmiphRUREJCWGEZLEb9ssgrY2NRX1TU0SVUNERFJiGCFJDAsMxF3R0cZ2SV0dPj51SsKKiIhIKgwjJJm2S8S/mZICg/2vwUdERBbGMEKSuX3AAMS12O35SlkZ/nfpkoQVERGRFBhGSDKCILQbHXkjJUWiaoiISCrcm4Yk1aTXI+rdd5FTVWU8Nn/kSLg4OcFHpcKc2FgkhoZy/xoiIgdk6uc3wwhJ7s3Dh/HM7t2dvh6vVmPznDkYFhhow6qIiKi3uFEeOYwJGk2Xr6fl5WHipk04V1Rko4qIiMiWGEZIUqIo4omdO7vtV9HQgEXbtsEBBvKIiMhMDCMkqaO5uUjLyzOpb2peHo7l5lq5IiIisjWGEZLUtosXzeq/1cz+RERk/xhGSFLlDQ1W7U9ERPaPYYQk5aNSmdX/QnExqhsbrVQNERFJgWGEJDUnNtas/vuzsjDgnXfw54MHUavVWqkqIiKyJYYRklRiaCji1Wqzzimtr8dze/Yg6t138VZKCnf7JSJycAwjJClBELB5zhx4d3O7RiFr/1e1qLYWv/32W0S9+y7eO3oUDTqdtcokIiIrYhghyQ0LDMTBRYs6HSFJUKuR/sgjOPzQQ5geFdXu9YKaGvxm507EvPcePkhLg1avt3bJRERkQVwOnuyGKIo4lpuLrRcvoryhAT4qFebGxmJcm71p9t+4gRf37sUPN250eJ0ILy+8MGkS5o8aBSe53FblExFRG9ybhvq87zMz8cLevTicnd3h61E+Pnhx0iQ8MHJkh7d5iIjIuhhGqF8QRRG7r13DC3v3dro66yA/P6yaPBnzhg2DnKGEiMhmGEaoXxFFETuuXMGL+/bhRH5+h32GBgTgpcmT8fOhQyFrcduHiIisg2GE+iVRFLHt0iWs2rcPpwsLO+wzIjAQL0+Zgrmxsa3mohARkWUxjFC/ZhBF/Pv8ebz0ww84X1zcYZ/RwcF4ZepUzIqJYSghIrIChhEiAHqDAV+cO4eXfvgBl0tLO+wzLjQUr0yZgjsHDmQoISKyIIYRohZ0BgM+PXMGL//wA66Vl3fYZ4JGg1emTsXUyEiGEiIiC2AYIepAk16Pj0+dwqv79+NGZWWHfSZHROCVqVMxKSLCxtUREfUtDCNEXdDq9dh08iT+eOAAcqqqOuwzLSoKr0yZgmSNxsbVERH1DQwjRCZo0Onw4YkTeO3AAeTX1HTYZ2Z0NF6eMgUJoaE2ro6IyLExjBCZob6pCR+kpeH1Q4dQVFvbYZ/Zgwbh5SlTMDokxMbVERE5JoYRoh6o1WqxLjUVfzl0CKX19R32+dmQIXhp8mSMCAqycXVERI6FYYSoF6obG/HesWN44/BhlDc0tHtdAPCLYcOwavJkDAkIsH2BREQOgGGEyAIqGxrw9pEjeOvIEVQ1NrZ7XQDwyxEjsGryZMT4+dm+QCIiO8YwQmRBZfX1eCslBe8cPYoarbbd63JBwIOjRuGFSZMQ5eMjQYVERPaHYYTICkrq6rDm0CGsTU1FXVNTu9cVMhkWxcXh+dtuQ4S3t+0LJCKyIwwjRFZUWFODPx86hPVpaWjQ6dq97iST4eExY/CH225DKP/OElE/xTBCZAN51dV4/eBB/O34cWj1+navK+VyPDJ2LFbcdhuC3d0lqJCISDoMI0Q2lF1ZidcOHMDGkyfRZDC0e91FocBjCQl4dsIEBLi5SVAhEZHtMYwQSeB6RQX+uH8/NqenQ9/Bf1puTk54Ytw4PDN+PPxcXSWokIjIdhhGiCR0tawMr+7fj09On4ahg//EPJyd8VRSEp5OSoKPi4sEFRIRWR/DCJEduFRSglf278e/zpxBR/+heSmVWJ6cjKeSkuCpVNq8PiIia2IYIbIj54uL8dK+fdhy/nyHr/u6uOCZ5GQ8kZgId2dnG1dHRGQdDCNEduh0YSFW7duHrRcvdvi6v6srnp0wAY8lJMDVycnG1RERWRbDCJEdO56Xh5d++AFfX77c4etBbm5YMXEiHomPh0qhsHF1RESWwTBC5ACO5uRg1b592HX1aoevqz088IeJE7FkzBgoGUqIyMEwjBA5kENZWXhx3z58n5nZ4esaT0+snDQJC+Pi4CyX27g6IqKeYRghckD7rl/Hi3v34kBWVoevR3p748VJk/DgqFFQyGQ2ro6IyDwMI0QOShRF7MnMxAt79+JITk6HfaJ9fbFq8mTcP3w45AwlRGSnGEaIHJwoitiZkYEX9+1DWl5eh31i/f2xavJk/GLYMMgEwXje0dxcbLt4EeUNDfBRqTAnNhaJoaEQbvYhIrIFhhGiPkIURfzv8mW8uHcvThUWdthnWEAAXp4yBYP8/PDQf//bYXiJV6uxec4cDAsMtHbJREQAGEaI+hyDKGLrxYtYtW8fzhYVddhHLggd7olzi7dKhYOLFjGQEJFNmPr5zZvNRA5CJgj42ZAhOPXoo/js5z9HrL9/uz5dBREAqGhowKJt2+AAv4MQUT/CMELkYGSCgHnDh+Ps0qX45Kc/RbSvr1nnp+bl4VhurpWqIyIyH8MIkYOSy2T41ciRuLBsGe6OiTHr3M6WoycikgLDCJGDU8hk0Jg5l+pCSQlv1RCR3WAYIeoDfFQqs/pvu3QJoz74AB+kpaG6sdFKVRERmYZhhKgPmBMba/Y5Z4qKsHT7doS+9RaWbd/e6RM6RETWxjBC1AckhoYiXq3u0bnVWi3eT0vDiPXrMXnzZnx+9iy0er2FKyQi6hzDCFEfIAgCNs+ZA+9ubtd4K5VYedttGN7JOiP7b9zA//v3vxH+179i5fffI6uy0hrlEhG1wkXPiPqQc0VFWLhtW4crsCao1dh0cwVWURRxMCsL76el4d/nz6PJYOjwejJBwOxBg/BYQgKmRUUZl5wnIjIFV2Al6qdEUcSx3FxsbbE3zdzYWIzrZG+awpoabDx5Eh+kpSG7qqrT6w708cHS+HgsjIuDn6urNb8FIuojGEaIyCx6gwHbr1zB+rQ07MzI6LSfSqHAvGHD8FhCAhLUam6+R0SdYhghoh7LKCvD39LS8FF6Osrq6zvtNzYkBI8lJOD/DR8OVycnG1ZIRI6AYYSIeq2+qQlfnDuH9WlpONrFEvLeKhUWjhqFpQkJGOTnZ8MKicieWXWjvHXr1iEyMhIqlQqJiYk4duyYSed99tlnEAQBc+fO7cnbEpGNuTg5YUFcHI4sWYK0hx/G4tGj4aJQtOtX0dCAt48exeC1azH9k0/w1YUL0HUyKZaIqC2zR0Y+//xzzJ8/Hx988AESExPx9ttvY8uWLbh06RICu9iW/Pr165g4cSKioqLg6+uLrVu3mvyeHBkhsh/l9fX4x6lTWJ+WhsulpZ32C/XwwK/HjsXDY8YgxMPDhhUSkb2w2m2axMREJCQkYO3atQAAg8EAjUaDJ554As8991yH5+j1ekyaNAkPPfQQDhw4gIqKCoYRIgcniiK+z8zE+2lp2HbxIvSd/FOikMnw09hYLI2Px5TISE54JepHTP38bj/e2gWtVovjx49jxYoVxmMymQzTpk1DSkpKp+e98sorCAwMxOLFi3HgwIFu36exsRGNLfbLqOricUMikoYgCLgjKgp3REUht6oKG06cwN+PH0d+TU2rfjqDAVvOn8eW8+cxxN8fS+PjMX/UKHiZuZ8OEfVdZs0ZKSkpgV6vR1BQUKvjQUFBKCgo6PCcgwcPYuPGjdiwYYPJ77N69Wp4eXkZvzQajTllEpGNhXp64qUpU3Djqaew5b77MDUyssN+F0pK8JudO6F+6y088r//Ib2TfzeIqH+x6nLw1dXVePDBB7Fhwwb4+/ubfN6KFStQWVlp/MrOzrZilURkKU5yOe4dOhTfL1iA8489ht+MGwdPpbJdv7qmJvz9xAmM/tvfMH7jRvzz9Gk06HQSVExE9sCsOSNarRaurq748ssvWz0Rs2DBAlRUVGDbtm2t+qenp2P06NGQy+XGY4abM+xlMhkuXbqEgQMHdvu+nDNC5LhqtVp8euYM3k9L63IkxM/FBYtHj8aj8fEY4ONjwwqJyFqsOoF13LhxeO+99wA0h4vw8HA8/vjj7SawNjQ0IKPNSo4rV65EdXU13nnnHQwaNAjOzs4W+2aIyH6Jooijubl4PzUVn5871+nOwAKAmTExeCw+HndFR0Mu436eRI7KKhNYAWD58uVYsGAB4uPjMW7cOLz99tuora3FokWLAADz589HaGgoVq9eDZVKheHDh7c639vbGwDaHSeivk0QBCSFhSEpLAxvzZiBTSdPYn1aGjIrKlr1EwHsuHIFO65cQYSXFx6Nj8fi0aMR4OYmSd1EZH1mh5F58+ahuLgYL774IgoKChAXF4edO3caJ7VmZWVBxt9kiKgL/q6u+N2ECfjt+PHYlZGB99PSsP3yZbQdpr1RWYkVe/Zg1b59uG/oUDyWkIDksDA+HkzUx3A5eCKyC9crKvD348fx4YkTKK6r67TfyKAgPBYfjwdGjoS7Cbd5iUg63JuGiBxSo06Hf1+4gPdTU3GoiyfpPJydseDmfjhDAwJsWCERmYphhIgc3unCQqxPTcUnp0+jtqmp036TIyLwWEIC5sbGwrnF03tEJC2GESLqM6oaG/HJqVN4Py0N54uLO+0X7O6Oh8eMwa/HjkUY/60gkhzDCBH1OaIo4kBWFt5PTcW/u9gZWCYIuGfwYDwWH487oqIg44RXIkkwjBBRn1ZQU4MPT5zA344fR04X+1fF+Pri0fh4LIyLg6+Liw0rJCKGEXI4oiiioTQdtTm7oddWQu7sBbew6VD5xfFRTuqUzmDA9suX8X5aGr69erXTfiqFAvcPH47HEhIQr1bbsEKi/othhBxKY8VlFB75HRrLTrd7Tek7EkFJa6D0HiRBZeRIrpSW4m/Hj+OjkydR3tDQab94tRqPxcdj3vDhcHVysmGFRP0Lwwg5jMaKy8jZfR8MTZ0PtcucPBE2fQsDCZmkvqkJn587h/dTU5Gal9dpPx+VCovi4vBofDxi/PzavX5rCfttFy+ivKEBPioV5sTGIjE0lKN1RCZgGCGHIIoisnfN7XBEpC2l70hoZmzlhwCZJS0vD+tTU/Hp2bNd7gw8PSoKjyUk4CeDBkEhk+FcUREWbtuGtA7CTLxajc1z5mBYYKA1SydyeAwjJDnR0ARDUw0MTdXQa6thaGrxdbOtrbqK6utbTb6m5s7/QOU/2npFU59VVl+Pf6SnY31aGq6UlXXaL8zTE3MHD8Ynp0+jsrGx037eKhUOLlrEQELUBYYRG+mLky5FUYSob7gZJKpg0FZD31RtDBY/holb7arm17XVMOhqjEFD1Hd+z76nvKIfQEDCqw77syXpGUQRe65dw/q0NGy7dAmGXvwTmKBW4+iSJfz7SNQJhhEbsMdJl6JouBkSOg4O+qaqDsLEra8aY6iA2PlwttQUbqFwDRoPl6DxcA1KhsI1SOqSyEFlV1Ziw4kT2HDiBApqanp0jSOLFyMxLMzClRH1DQwjVmaNSZeiock4uvDjbY2qdsHBOEqhbR0kbv0v2u192rc5e0bDJSgZrsHj4RKYBLnSW+qSyMFo9XpsvXgR69PSsO/6dbPOfW7CBKyeNs06hRE5OIYRKzJn0qXCLQxegxZAbDMKoW8xb+JWkLDGbQ1bEmTOkDl53Pxyh8zZo1Vb7uTR5pgHmmrzUZy6wpJVQOkzrDmYBI2HS0A8ZE5uFrw+9XXztmzBF+fPm9w/3MsLz06YgLuioxHl42PFyogcj6mf3wob1tRnNJSmmxREAEBXm4PSk3+yckW9JyhcIXPyaA4MTu7NYaFNcJA5eUDu3CJs3Dp+65hcafb7iqKIqqv/MunnKXcJhpPHADSWHIdo0HZ2RTSWn0Vj+VmUX/g7ICig8o+Da9B4uAaPh9Ivrkd1Uv9hbqDIqqzEsh07AACD/Pxw18CBmBkTg8kREXDhGiZEJuHISA+UpP8F5efXS11GM0EGmaLtKIRHm1GI1sFBbmx7NvdRuEGQSZdLzb3lZdA1oKHkBOoKD6G+IAUNZacBUW/SewlyFVwCEuAS3DzfROkzHIKMu7zSj47k5CB548ZeX0elUGBKZCRmRkfjruhoxPj6cqIr9Tu8TWNFhceeR1XGp72+jiBzvhkG2o5CtL2l0TJMeP74upMHBIVrn/gHrjeTgfVN1agvOob6ghTUFR6CtuKiye8rc/KAS1CScUKss1dMn/h5Us+JoohxH37Y4foibSlksk4362srysfHGEymRkbCzdm5t6US2T2GESsyd2TELWwGvAfNbx8ueLugFVEU0ViajpoWj0m7h02H0szHpHUNpagvTEFdYQrqCw+jqfq6yefKVf7Gp3RcgyfAyV3Tg++EHN25oiJM3LQJFV0sKe+tUmH/woVo1OvxzZUr2Hn1Ko7k5Jj0qLCzXI5JERHGcDLE358hmPokhhErqi85iZxvf2Zyfy7UJa2m2lzUFx5BXcEh1BUehr6+0ORzFW5hxsmwrkHJULhwgav+oqsVWBPUamzqYAXWsvp6fHftGr7JyMDOjAyTHxcO9/IyBpM7BgyAh5K/qFDfwDBiRVzC3HGJooim6kzUFR5GfcFh1BUdgaGx3OTznb1imh8jDpoAl6BEyJ29rFgtSU0URRzLzcXWFnvTzI2NxTgT9qYRRRGnCguNoyaHsrKgN+GfW4VMhonh4cZwMiIwkP9+kMNiGLEybu7WN4iiAdqKi6grONwcUIqOQdTVmni2AKXv8JvzTZLhEpgAmcLVqvWS46psaMCezExjOMmp6vzfjpZCPTxw181gMi0qCt4qlZUrJbIchhEbsMcVWKl3REMTGkpPo77wMOoKDqOh5EQXjxG3IXOCyi8OrsET4BqU3LwlgJyTFKk9URRxrrgYOzMy8E1GBg7cuIEmEybCygUByRqNcdQkLjgYMo6akB1jGLERS026JPvU/BjxcdQVHEZ94eGbjxGb9vSEIHeBS2DCzdVhJ0DpPZSPEVOHarRafH9z1OSbjAzcqKw06bwgNzfjqMmdAwfC18XFypUSmYdhhMgK9Nqq5seIC289RnzJ5HNlzl5wCUz68Ukdz4EMrNSOKIq4VFpqHDX54fp1NOq7X0dHJggYFxpqHDWJV6s5akKSYxghsgFdQ0nzkzqFh1FfkIKmmusmnytXBTTPNwkeD9eg8XBy52Zr1F5dUxP2Xb9unGuSUVZm0nn+rq64c+BAzIyOxoyBAxHgxm0RyPYYRogk0FSb0+Ix4hSzHiN2cg+/+aRO84RYhUuAFSslR5VRVmYcNdmbmYl6Xfc7bAsAxqrVxlGTxNBQyGUy6xdL/R7DCJHEmh8jvmacb1JXeAQGbYXJ5zt7Dbo5cpLcvBuxs2l/90VRRENpOmpbzGNyC5vePKGWw/Z9SoNOh/03bhhHTS6WlJh0no9Khek3R03uio5GsLu7lSul/ophhMjOiKIBjeUXUF94CHUFKagvPgZRV2fayYIMSp/hrXcjVrSfrMgnvPq3zPJy7Lp6Fd9kZGDPtWuobWoy6by44GBjMEkOC4OTnBOtyTIYRojsXPNjxKd+fFKn5KTJjxELMmeo/EcbV4ZV+Y2Ctvo6174ho0adDoeys42jJmeLikw6z1OpxLSoKGM4CeO/udQLDCNEDsagqzc+RlxXeBiNZWdMfowYchfIZAoYmqq77cpVgfun7MpK46jJd9euoaqx0aTzhgcGGoPJxPBwOHPUhMzAMELk4JofIz7a/BhxwWFoK01/jLg73C+pf2vS65GSk2McNUkvKDDpPHdnZ9w+YABmRkdjZnQ0Iry9rVsoOTyGEaI+Rldf/ONjxIUpaKq50eNr+QxdCv+431uwOnJk+dXVxlGTb69e7XK34pZi/f2NoyaTIiKgUig67SuKIo7m5mJbi31+5sTGItGEfX7IcTGMEPVxTbU5zRNhCw+hJnsXRL1pHyAAoPIfi5CJ66BwDbJiheSIdAYDjuXmGkdNOtq1uCMuCgWmthg1Gejra3ytqx2Q49VqbO5gB2TqGxhGiPqR4pN/RsWFD8w8S4AqIB4e4bPgHj4TChd+GFB7RbW1+PbmqMmujAyU1tebdF60ry9mRkdjiL8//vD9912OtnirVDi4aBEDSR/EMELUj9SXnETOtz/rxRUEuASOg3v4LLhr7uKCa9QhvcGA4/n5xlGTozk5sNQHSIJajaNLlvCWTR/DMELUj4iiiOxdcztcX8RsggwugUnwCJ8FN80MKFR+vb8m9UmldXX49upV7Lx6FTszMlBUW9ur6x1ZvBiJYdwWoS9hGCHqZxorLpu0zkhg4utoLDuLmqzt3U+CFWRwCUpuvpUTNgNylW/X/anfMogi0gsKjKMmKdnZ0Jv58fJYfDzWzZplpQpJCgwjRP2QOSuwiqKIxvJzqMnajuob26Grze764oIcrkHj4R5xM5gova3wHVBfUV5fj198+SW+u3bNrPNGBgVhVkwMZsXEICksjHvoODiGEaJ+ShRFNJamo6bF3jTuYdOh7GJvGlEU0Vh2pjmYZG2Hrja36zcRFHANngCPiJ/ALWw65M5eVvhOyNGt+O47vH7oUI/P93VxwV3R0ZgVE4O7oqPh69J+CwSybwwjRNQjt8JMddZ21GTtgK4uv+sTZE5wDb4NHuF33wwm/G+Umh3JyUHyxo0WuZZMEJAcFtY8ajJoEEYEBnKyqwNgGCGiXhNFAxpK0lFzK5jUd71SpyBzhmvIbXAPnwW3sGmQO3nYqFKyR6IoYtyHH5q0VonawwOBrq5ILyw06doaT0/cffN2zh1RUXB1cuptuWQFDCNEZFHNweQEam5sR3X2Dujru954TZA5w1U9uflx4dA7IHPiNvX90bmiIkzctMnkdUbyqqux48oVbL9yBbuvXjVp52GlXI6pAwYY55oM8PGx5LdAvcAwQkRWI4oGNBSnofrG16jJ/gb6hpIu+wtyJVzVU5sfF1ZPhczJzUaVkj3oagXWBLUamzpZgbVRp8P+Gzew/WY4ySgrM+n9hvj7G2/nTNBo4MTN/STDMEJENiEa9KgvTr15K+cb6BtLu+wvyFVwU0+Fe8TNYKJwtVGlJCVRFHEsNxdbW+xNMzc2FuPM2Jvmcmkptl++jO1XrmD/jRtoMnS/q7WXUok7Bw7ErJgYzIyJQaAbg7AtMYwQkc2JBh3qi46hOms7arN3Qt/Y9W+ygtwFbqG3N88xUU+BTMGnJfoqURTRUJqO2hZPebmFTYeqi6e8ulLd2Ijd165h++XL2JGRgYKamm7PEQCMCw01jprEBQdDxkmwVsUwQkSSEg061BWmNI+YZO+CQVvRZX9B4Qq30DvgET4LriGTIVOobFMoWZ0569/0hEEUcTI/33g7JzU316Rl6kPc3Y2TYKdFRcFDqexxDdQxhhEishuioQl1BYdRk7UDNTm7YNBWdtlfULjBPWwa3MNnwTVkEmRyfkg4KlNXBg6bvqVXgaSlotpafHMzmOy6ehVVjY3dnuMkk2FyZKRxEmyMH7dBsASGESKyS6Jei7rCwzdv5eyCoam6y/4yJw+4hU6De8QsuAZPZDBxIObsmaT0HQnNjK0WXzukSa/Hoexs41yTCyVdT7a+JcbX13g7Z1JEBJw5CbZHGEaIyO4Z9I2oLzjUHExydpsWTMLubL6VEzwBgtzZRpVSd0SDDrq6fDTVZKOpNhtNNdloKD2F+oKDJl9Dc+d/oPIfbcUqgczycuPtnL2ZmWjU67s9x93ZGdOjojArJgZ3x8QgxIPr55iKYYSIHIpB34i6/P3Nc0xyvoOo63oHWJmTJ9w1M5pv5QSPhyDjolfWJIoi9A0laKrNga4mG001WTdDRw6aarKhq8sDxO4/2LviM3Qp/ON+b6GKu1er1eL7zExjOMmp6vxWUktjQkKMt3MSQkM5CbYLDCNE5LAMugbU5e9vHjHJ/Q6irq7L/jJn7x+DSVAyBJnCRpX2Lfqm6ptBI8c4uqEzjnTkQNTXW/X93TV3I+S2dVZ9j86IoogzRUXG2zkpOTkwmPDxGODqipk3g8mdAwfCW8WJ1y0xjBBRn9AcTPah+sZ21Obu6fYDUa70hZtmBjzCZ8ElMJHBpAVRr0VTbS6aarOhq8lpPbpRmw1DY7nUJcJNcxf8hj8Bpc9QSesoravDrqtXsf3KFezMyEBZffdBTC4ImBgebpxrMsTfv9/vn8MwQkR9jkFXh9q8vai5sR21eXsh6jtfYhwA5Eo/uGvugnvELLgEjIMg69uTEEXRAH19UfO8jZosNNXevIVya5SjrgAw6aFX88iVvlC4a+DkpoGTuwZO7mFQuGlgaKpGwcFlPbqmW9id8B3+BFS+wy1crfl0BgOO5uQYb+ecNnH/nEhvb+PtnKkDBkCl6H/BmGGEiPo0Q1MtavP2ojprO+ry9kLUd/34plzlD3fNXfCI+AlU/vEOGUxEUYRBW9nmFsrNEY6abOhqcyEatBZ/X0HhejNohMHJTQOFe3jz/3fXwMktrNN9h8x5mqYzbqF3wHf4b6DyG9nja1hadmWlcf+c765dQ71O1+05LgoF7rg5CXZWTAw0Xl42qFR6DCNE1G8YmmpQm/v9zWCyr9sPZLlLINw1M+ERPguqgLEQBFmH/Sy9aqgpDLoG6G6OaLS8jXJrdKO7J456RFDAyU0NhXFkQ2MMHwp3DeRKvx5/v6atM+IBd80sVGf9r9OJy67qqfAb/huo/ON6VIe1NOh02Hf9OrZfvoyvr1zB9YoKk84bERhovJ2TFBYGhazjv4OOjmGEiPolfVM1anP2oCbra9TlHzAhmATBI/xuuIfPgsp/tDGYWGvV0OZHYAs6mCDa/KVvKDb7mqaQuwS2Gd3QwOnmCIfCJdiqc2tM/VnqG8tRcfEjVFz+R6ehyzVkMnyH/wYuAWOsVm9PiaKICyUlxkmwB7OyoDfhI9bXxQV3RUdjVkwM7oqOhq9L59siiKKIo7m52NZij585sbFINGOPH1tiGCGifk+vrUJtzm5UZ+1AXcEBwND1dvQK1xC4a+6G0m8EilNf7NGqoaIoQt9Y2uaplKwfRzdq8wCx+2F9c8mcPODkrulgdEMDhVuY5Mvri6KIxtJ01LQYZXIPmw5lB6NMem1lcyi5tKnzUBI8Eb4jnoRLQLwtyu+RioYGfHtzEuw3V66guK7rp8IAQCYISA4LM46ajAgMNP58utr9OF6txuZOdj+WEsMIEVELem1lczC5sR11BQctEgicPCLhGf0r6GtzWj2V0t2jyD0hyJyhuDmqcWuuxo+jGxrInfveHAS9tgoVlzaj4uLGToOhS9B4+I34DVwCE21cnXkMoojU3FzjJNgT+fkmnafx9MTdMTEYERiIlXv3oqKh80nb3ioVDi5aZFeBhGGEiKgT+sYK1OR8i5obX6Ou8HCvF+uyDAEK1xDjkyi3bqHcCh9yl8BO57b0dXptFSovf4zyixs73XDRJTCxeaQkMMkub1e0lV9dbZwEu/vaNdRoLTPxOEGtxtElS+zmZ8AwQkRkAn1DGWpydqE6azvqC1MA0WC195IpfVo8/qq5OXcjrDl4uKq5vH03DE01qLj8McovftjpmiiqgAT4jXgSLkHj7eYDuTuNOh0OZGUZ55pcKSvr1fWOLF6MxLAwC1XXOwwjRERm0jWUIv/AUjQUp/bofEHu0sEtlB9HNzp7BJbMY2iqRcWVT1Bx4UPoG0s77KMKiIfv8CfgGnybw4SSW66Ulhpv5/xw/TqaDOYF5OcmTMDqadOsVJ15GEaIiHqgJP0vKD+/3uT+bqHT4DPsseZbKb14BJbMZ9DVofLK/6H8wt+gb+gklPiNhu+I38A1ZLJD/tlUNzbi3i++wLfXrpl8ziNjx+KDn/zEilWZztTP7/55A5KIqBNuYdPN6u877DG4+I+GQsWlv21NpnCFz5CHEXnPAfiPWQm5KqBdn4bSk8jbtwjZ3/4UtbnfwwF+/27FQ6nEmJAQs87xccD9cRhGiIhaUPnFQelr2mqfSt+RUPrFWbcg6pZM4QKf2MWIvGc/Asa+CLlLULs+jaWnkPfDYmTvmoOanN0OFUrmxMaa1X+umf3tAcMIEVELgiAgKGkNZE5d3xKWOXkiKGkNR0PsiEyhgvfgRYi85wcExL8MhUtwuz6NZWeQv//XyN75E9Rk74JoxQnLlpIYGop4tdqkvglqNcaFhlq5IstjGCEiakPpPah5QbNORkiUviM7XPCM7INMroT3oPmIuGcfAhJehcK1/Qd5Y/l55B94FFnfzEJ11jd2HUoEQcDmOXPg3c3tF2+VCpvmzHHIgMwJrEREnTBn1VCyXwZ9I6oz/42yc+9DV5vbYR9nr8HwHf443MPvttv1XLpagTVBrcYmrsBqXQwjRETUW6Jei6rrX6Hs7DroarM77OPsFQPfYY/DPXyWXe7sLIoijuXmYmuLvWnmxsZiXH/cm2bdunVYs2YNCgoKMGrUKLz33nsYN25ch303bNiAjz/+GGfPngUAjB07Fq+99lqn/TvCMEJERJYiGppQlbkV5efWoanmRod9nDwHwnfY4/CImG2XocRRWO3R3s8//xzLly/HqlWrcOLECYwaNQozZsxAUVFRh/337duH+++/H3v37kVKSgo0Gg3uvPNO5OZ2PFRGRERkTYLMCV4D70PET75DUNIbcPKIbNenqeoqClOexo3t01F17d8QDZbf3JB+ZPbISGJiIhISErB27VoAgMFggEajwRNPPIHnnnuu2/P1ej18fHywdu1azJ8/36T35MgIERFZi2jQofrG1yg79x6aqjpeXMzJPRK+w5fBI3IOBJmTjSt0XFYZGdFqtTh+/DimtVhmViaTYdq0aUhJSTHpGnV1dWhqaoKvr2+nfRobG1FVVdXqi4iIyBoEmQKeA+Yi4u5vETz+HTh7Rrfr01RzHYVHfocbX09D5dXPIRqaJKi07zIrjJSUlECv1yMoqPWCMkFBQSgoKDDpGs8++yzUanWrQNPW6tWr4eXlZfzSaDTmlElERGQ2QSaHR+Q9CJ+1C8ET3oOzV/tHt5tqslB09Dlc/9/tqMz4FKLeMrvt9nc2fX7p9ddfx2effYavvvoKqi6el16xYgUqKyuNX9nZHc96JiIisjRBkMEj4icIv/sbBE9cB2fvwe366GpzUHTseVz/31RUXPk/GPSNElTad5gVRvz9/SGXy1FYWNjqeGFhIYKD269019Ibb7yB119/Hd9++y1Gjux6qWWlUglPT89WX0RERLYkCDJ4hN+N8Jk7EHLbB1D6DG3XR1eXh+LUlbjxv6mouPwxQ0kPmRVGnJ2dMXbsWOzZs8d4zGAwYM+ePUhOTu70vL/85S949dVXsXPnTsTHx/e8WiIiIhsTBBncNTOguetrhEz6O5Q+w9v10dXlozhtFa7/dzIqLm2GQdcgQaWOy+zbNMuXL8eGDRvwj3/8AxcuXMDSpUtRW1uLRYsWAQDmz5+PFStWGPv/+c9/xgsvvICPPvoIkZGRKCgoQEFBAWpqaiz3XRAREVmZIAhwD5sOzV3/hXryxg63C9DXF6L4+Mu4/t9JKL/4EQy6egkqdTwKc0+YN28eiouL8eKLL6KgoABxcXHYuXOncVJrVlYWZLIfM8769euh1Wpx7733trrOqlWr8NJLL/WueiIiIhsTBAFuobfDVT0Vdfk/oOzMO2goTW/VR99QjJITr6L8/Hr4DPk1vGIegEzhKk3BDoDLwRMREfWCKIqoKziAsjPvoqHkeId95Eo/+Ax5GF4xv4LMyc3GFUqHe9MQERHZkCiKqC88jNIz76ChOLXDPnKlL7xjl8B70IOQObnbuELbYxghIiKSgCiKqC86grIz76C+6GiHfWTO3vCJXQyvwQsgd/KwcYW2wzBCREQksbrCIyg7+x7qCw93+LrM2Qvegx+C9+CFkDv3vc83hhEiIiI7UV+UirKz76Ku4GCHr8ucPJpDSewiyJ29bFyd9TCMEBER2Zn64hMoO/sO6vL3d/i6zMkD3oMWwDt2MeRKb9sWZwUMI0RERHaqoeQkSs++h7q8vR2+LlO4w2vwfPgMXgy56seNZUVRRENpOmpzdkOvrYTc2QtuYdOh8ouDIAi2Kt9kDCNERER2rqH0NMrOvova3D0dvi4oXOE9aD68Y5dA31CKwiO/Q2PZ6Xb9lL4jEZS0Bkrv9pv7SYlhhIiIyEE0lJ1tDiU5uzvuIFNCgAjR0PkuwTInT4RN32JXgcTUz2+b7tpLRERE7al8h0M96e8In7kdbpq72ncwNHYZRADA0FSFwiO/gwOMMbTDMEJERGQnlD5Dob5tPcLv/gbu4XcDMG8eSGPZaTS2WZreETCMEBER2RmldyxCJq5D+N074eQ50Kxzazq71WPHGEaIiIjslNJ7EFwCE806R6+ttFI11sMwQkREZMfMXQTNERdNYxghIiKyY25h083q725mf3vAMEJERGTHVH5xUPqONKmv0ncklH5x1i3IChhGiIiI7JggCAhKWgOZU9frbMmcPBGUtMYuV2LtDsMIERGRnVN6D2pe0KyTERKl70i7W/DMHAqpCyAiIqLuKb0HQTNjKxpL01HTYm8a97DpUNrp3jSmYhghIiJyEIIgQOU/Gir/0VKXYlG8TUNERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgk5RCLnomiCACoqqqSuBIiIiIy1a3P7Vuf451xiDBSXV0NANBoNBJXQkREROaqrq6Gl5dXp68LYndxxQ4YDAbk5eXBw8PDbtfer6qqgkajQXZ2Njw9u95ZkbrGn6Vl8OdoOfxZWg5/lpbhKD9HURRRXV0NtVoNmazzmSEOMTIik8kQFhYmdRkm8fT0tOu/GI6EP0vL4M/RcviztBz+LC3DEX6OXY2I3MIJrERERCQphhEiIiKSFMOIhSiVSqxatQpKpVLqUhwef5aWwZ+j5fBnaTn8WVpGX/s5OsQEViIiIuq7ODJCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjvbR//37Mnj0barUagiBg69atUpfkkNavX4+RI0caF/BJTk7GN998I3VZDumll16CIAitvmJjY6UuyyFFRka2+1kKgoBly5ZJXZrDqa6uxlNPPYWIiAi4uLhg/PjxSE1Nlbosu9fdZ8x//vMf3HnnnfDz84MgCEhPT5ekzt5iGOml2tpajBo1CuvWrZO6FIcWFhaG119/HcePH0daWhpuv/12zJkzB+fOnZO6NIc0bNgw5OfnG78OHjwodUkOKTU1tdXPcffu3QCA++67T+LKHM+SJUuwe/dufPLJJzhz5gzuvPNOTJs2Dbm5uVKXZte6+4ypra3FxIkT8ec//9nGlVkWH+21IEEQ8NVXX2Hu3LlSl9In+Pr6Ys2aNVi8eLHUpTiUl156CVu3bnXY35Ds2VNPPYWvv/4aV65csdt9suxRfX09PDw8sG3bNsyaNct4fOzYsZg5cyb++Mc/Slid4+jqM+b69esYMGAATp48ibi4OJvX1lscGSG7o9fr8dlnn6G2thbJyclSl+OQrly5ArVajaioKDzwwAPIysqSuiSHp9Vq8c9//hMPPfQQg4iZdDod9Ho9VCpVq+MuLi4ctSMADCNkR86cOQN3d3colUo8+uij+OqrrzB06FCpy3I4iYmJ2Lx5M3bu3In169cjMzMTt912G6qrq6UuzaFt3boVFRUVWLhwodSlOBwPDw8kJyfj1VdfRV5eHvR6Pf75z38iJSUF+fn5UpdHdoBhhOzG4MGDkZ6ejqNHj2Lp0qVYsGABzp8/L3VZDmfmzJm47777MHLkSMyYMQM7duxARUUFvvjiC6lLc2gbN27EzJkzoVarpS7FIX3yyScQRRGhoaFQKpV49913cf/993e5rTz1H/xbQHbD2dkZ0dHRGDt2LFavXo1Ro0bhnXfekbosh+ft7Y1BgwYhIyND6lIc1o0bN/Ddd99hyZIlUpfisAYOHIgffvgBNTU1yM7OxrFjx9DU1ISoqCipSyM7wDBCdstgMKCxsVHqMhxeTU0Nrl69ipCQEKlLcVibNm1CYGBgq8mX1DNubm4ICQlBeXk5du3ahTlz5khdEtkBhdQFOLqamppWv3FmZmYiPT0dvr6+CA8Pl7Ayx7JixQrMnDkT4eHhqK6uxqeffop9+/Zh165dUpfmcJ555hnMnj0bERERyMvLw6pVqyCXy3H//fdLXZpDMhgM2LRpExYsWACFgv9k9tSuXbsgiiIGDx6MjIwM/O53v0NsbCwWLVokdWl2rbvPmLKyMmRlZSEvLw8AcOnSJQBAcHAwgoODJam5R0Tqlb1794oA2n0tWLBA6tIcykMPPSRGRESIzs7OYkBAgHjHHXeI3377rdRlOaR58+aJISEhorOzsxgaGirOmzdPzMjIkLosh7Vr1y4RgHjp0iWpS3Fon3/+uRgVFSU6OzuLwcHB4rJly8SKigqpy7J73X3GbNq0qcPXV61aJWnd5uI6I0RERCQpzhkhIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJKn/D825zIWrfoSDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values_try = [1,3,5,7,9,11]\n",
    "results_train, results_val = get_models_knn(keep_data, values_try)\n",
    "point_plot(results_train, results_val, values_try)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c89af",
   "metadata": {},
   "source": [
    "__CONCLUSION__: <br>\n",
    "It seems that the best value of number of neighbors to keep is 5 neighbors.It has less overfitting and the best f1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4308c4",
   "metadata": {},
   "source": [
    "__`Step 14`__ - Create an instance of the model chosen for the algorithm KNN named as `final_model_knn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "035d4851",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_knn = KNeighborsClassifier(n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644013d7",
   "metadata": {},
   "source": [
    "__OTHER IMPORTANT HYPERPARAMETERS:__\n",
    "\n",
    "|Parameter| Definition | Options | Default | \n",
    "|---|---|---|---|\n",
    "| weights| Weight function used in prediction. | Uniform, Distance | Uniform |\n",
    "| algorithm | Algorithm used to compute the nearest neighbors. | ball_tree, kd_tree, brute, auto | auto |\n",
    "| metric | Metric to use for distance computation. | Callable | Euclidean Distance |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a61f39ed-47bf-4cfc-a754-8a6f68798be5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<a class=\"anchor\" id=\"6th-bullet\">\n",
    "\n",
    "### 4.2.2. Decision Tree\n",
    "\n",
    "<a class=\"anchor\" id=\"7th-bullet\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292d0e00-b546-477a-a29d-c2fcf5d9a281",
   "metadata": {},
   "source": [
    "\n",
    "#### 4.2.2.1 RandomSearch\n",
    "    \n",
    "</a>\n",
    "\n",
    "RandomizedSearchCV is a function provided by Scikit-learn (sklearn) that is used for hyperparameter tuning. While GridSearchCV exhaustively explores all possible combinations of hyperparameters, RandomizedSearchCV randomly samples a specified number of combinations from the parameter grid.\n",
    "\n",
    "The random sampling of parameter combinations makes RandomizedSearchCV more efficient than GridSearchCV for large hyperparameter spaces.\n",
    "\n",
    "Similar to GridSearchCV, RandomizedSearchCV returns the best set of hyperparameters based on a specified performance metric. The best hyperparameters can then be used to train a final model on the full dataset for making predictions.\n",
    "\n",
    "__NOTE:__ RandomizedSearch do the process of cross validation inside the method itself. In this way, we are going to use the full data set and do all the needed changes and transformations on the data before applying the RandomizedSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9972cd37",
   "metadata": {},
   "source": [
    "__`Step 15`__ Create a copy of keep_data named as `data` and define the independent variables as `X_data` and the target as `y_data`. Transform the data as needed by calling the function `transform_data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cae482b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keep_data.copy()\n",
    "\n",
    "X_data = data.drop(['DepVar'], axis = 1)\n",
    "y_data = data['DepVar'].copy()\n",
    "\n",
    "X_data = transform_data(X_train = X_data, X_2nd_df_flag = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011607b9",
   "metadata": {},
   "source": [
    "__`Step 16`__ Create an instance of DecisionTreeClassifier named as `dr` with `max_depth = 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cc7c089",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = 3, random_state = 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c8a6d9",
   "metadata": {},
   "source": [
    "__IMPORTANT HYPERPARAMETERS:__\n",
    "\n",
    "|Parameter| Definition | Options | Default |\n",
    "|---|---|---|---|\n",
    "| criterion| The function to measure the quality of a split. | gini, entropy, log_loss | gini |\n",
    "| max_depth| The maximum depth of the tree. . |  _int_ or _float_ | None |\n",
    "| min_samples_split | The minimum number of samples required to split an internal node. | _int_ or _float_ | 2 |\n",
    "| min_samples_leaf | The minimum number of samples required to be at a leaf node.  | _int_ or _float_ | 1 |\n",
    "| max_leaf_nodes | The maximum number of leafs the tree can have.   | _int_ | None |\n",
    "| min_impurity_decrease | A node will be split if it induces a decrease of the impurity greater than or equal to this value. | _float_ | 0.0 |\n",
    "| splitter | The strategy used to choose the split at each node. If random,  the algorithm selects a random subset of features and finds the best split among them. | _best_ or _random_ | _best_|\n",
    "| max_features | The number of features to consider when looking for the best split. | _int_, _float_, _sqrt_, ... | None |01 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93a73d8",
   "metadata": {},
   "source": [
    "__`Step 17`__ Define a dictionary named as __parameter_space_random__ and define the following options to be considered during modelling:\n",
    "- 'criterion': ['gini', 'entropy'],\n",
    "- 'max_depth': [2, 3, 4, 5],\n",
    "- 'min_samples_split': [2, 4, 6, 8, 10],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddb74c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space_random  = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 4, 6, 8, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c84d155",
   "metadata": {},
   "source": [
    "__`Step 18`__ Create an instance of RandomizedSearchCV named as __random_search__ and pass as parameters the model __nn__, the __parameter_space_random__, define `scoring = f1`, `cv = 5` and `random_state = 42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbc0f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(dt, param_distributions=parameter_space_random, \n",
    "                                   scoring = 'f1', cv=5, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a75b9c",
   "metadata": {},
   "source": [
    "__`Step 19`__ Fit your instance to __X_data__ and __y_data__. <br>\n",
    "Call the attribute __best_params___ to check which is the best combination of parameters<br>\n",
    "Call the attribute __best_score___ to obtain the mean cross-validated score of the best_estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81d19a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'min_samples_split': 4, 'max_depth': 3, 'criterion': 'gini'}\n",
      "Best Score:  0.3436489277985441\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(X_data, y_data)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print(\"Best Hyperparameters: \", random_search.best_params_)\n",
    "print(\"Best Score: \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174b83c",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"8th-bullet\">\n",
    "\n",
    "#### 4.2.2.2. GridSearch\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92e7dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 4, 6, 8, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66db126",
   "metadata": {},
   "source": [
    "__`Step 20`__ Create an instance of GridSearchCV named as __grid_search__ and pass as parameters the model __nn__, the __parameter_space_grid__, define `scoring = f1` and `cv = 5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc0872ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(dt, parameter_space_grid, scoring = 'f1', return_train_score = True, cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d4b22d",
   "metadata": {},
   "source": [
    "__`Step 21`__ Fit your instance to __X_data__ and __y_data__. <br>\n",
    "Call the attribute __best_params___ to check which is the best combination of parameters<br>\n",
    "Call the attribute __best_score___ to obtain the mean cross-validated score of the best_estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92f5f083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Best Score:  0.3436489277985441\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_data, y_data)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda859b9",
   "metadata": {},
   "source": [
    "__`Step 22`__ Create an instance of the model chosen for the algorithm DecisionTreeClassifier named as `final_model_dt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f37db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_dt = DecisionTreeClassifier(criterion = 'gini', max_depth = 3, min_samples_split = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19507eca",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a class=\"anchor\" id=\"10th-bullet\">\n",
    "\n",
    "### 4.2.3. Select the winner model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b67202",
   "metadata": {},
   "source": [
    "\n",
    "<a class=\"anchor\" id=\"11th-bullet\">\n",
    "\n",
    "#### 4.2.3.1. COMPARE THE PERFORMANCE\n",
    "    \n",
    "</a>\n",
    "\n",
    "Let's compare our final models:\n",
    "\n",
    "__`Step 23`__ Compare the models using the function defined previoulsy `show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9af2536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Best KNN</th>\n",
       "      <td>0.434+/-0.04</td>\n",
       "      <td>0.3+/-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best DT</th>\n",
       "      <td>0.381+/-0.02</td>\n",
       "      <td>0.351+/-0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Train    Validation\n",
       "Best KNN  0.434+/-0.04    0.3+/-0.03\n",
       "Best DT   0.381+/-0.02  0.351+/-0.03"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_models = pd.DataFrame(columns = ['Train','Validation'], index = ['Best KNN','Best DT'])\n",
    "show_results(df_final_models, keep_data, final_model_knn, final_model_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b7332",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"12th-bullet\">\n",
    "\n",
    "#### 4.2.3.2. PLOT A ROC CURVE\n",
    "    \n",
    "</a>\n",
    "\n",
    "__`Step 24`__ Now we are going to compare our models using a ROC CURVE. To plot a ROC Curve, we need to create just one single model, and not several as we have when we apply StratifiedKFold.\n",
    "\n",
    "Create a copy of `keep_data` as `data` and define your independent variables as `X_data` and your target as `y_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "094b1f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keep_data.copy()\n",
    "\n",
    "X_data = data.iloc[:,:-1]\n",
    "y_data = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4433350",
   "metadata": {},
   "source": [
    "__`Step 25`__ Split your dataset into train and validation using train_test_split, where `train_size = 0.8`, `random_state = 99` and `stratify = y_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81706e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, \n",
    "                                                  train_size = 0.8, \n",
    "                                                  random_state = 99, \n",
    "                                                  stratify = y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f1b3f9",
   "metadata": {},
   "source": [
    "__`Step 26`__ Apply the needed transformations by calling the `transform_data` function and fit your three models in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0db9a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = transform_data(X_train, X_val, X_2nd_df_flag = True)\n",
    "\n",
    "model_knn = final_model_knn.fit(X_train, y_train)\n",
    "model_dt = final_model_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ebe99",
   "metadata": {},
   "source": [
    "__`Step 27`__ Use the `.predict_proba()` method of `modelknn` to obtain the probability estimates for the `X_val` and assign it to the object `prob_modelKNN`. Do the same for the other models, and assign it to `prob_modelDT` and `prob_modelNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fad6264",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_modelKNN = model_knn.predict_proba(X_val)\n",
    "prob_modelDT =  model_dt.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "862d685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n",
      "[[0.85365854 0.14634146]\n",
      " [0.38461538 0.61538462]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.875      0.125     ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.875      0.125     ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.8125     0.1875    ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.38461538 0.61538462]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.38461538 0.61538462]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.85365854 0.14634146]\n",
      " [0.875      0.125     ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.42857143 0.57142857]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.42857143 0.57142857]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.875      0.125     ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.         1.        ]\n",
      " [0.875      0.125     ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.38461538 0.61538462]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.38461538 0.61538462]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.38461538 0.61538462]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.42857143 0.57142857]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.875      0.125     ]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.875      0.125     ]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.8125     0.1875    ]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.38461538 0.61538462]\n",
      " [0.875      0.125     ]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.875      0.125     ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.42857143 0.57142857]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.42857143 0.57142857]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.38461538 0.61538462]\n",
      " [0.98484848 0.01515152]\n",
      " [0.875      0.125     ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.38461538 0.61538462]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.38461538 0.61538462]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.42857143 0.57142857]\n",
      " [0.8125     0.1875    ]\n",
      " [0.875      0.125     ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.85365854 0.14634146]\n",
      " [0.98484848 0.01515152]\n",
      " [0.98484848 0.01515152]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.98484848 0.01515152]\n",
      " [0.7260274  0.2739726 ]\n",
      " [0.98484848 0.01515152]]\n"
     ]
    }
   ],
   "source": [
    "print(len(prob_modelDT))\n",
    "print(prob_modelDT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "108ee837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n",
      "[[1.  0. ]\n",
      " [0.4 0.6]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [0.2 0.8]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [0.8 0.2]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.4 0.6]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.4 0.6]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [0.4 0.6]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [0.8 0.2]\n",
      " [0.6 0.4]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [0.8 0.2]\n",
      " [0.8 0.2]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [0.8 0.2]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [0.4 0.6]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.4 0.6]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.4 0.6]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.6 0.4]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [0.8 0.2]\n",
      " [0.8 0.2]]\n"
     ]
    }
   ],
   "source": [
    "print(len(prob_modelKNN))\n",
    "print(prob_modelKNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff8e2b0",
   "metadata": {},
   "source": [
    "__`Step 28`__ Call roc_curve() for the three different models. In this way, you should: <br>\n",
    "1) For the first roc curve, call the roc_curve metric and define the arguments `y_true` equal to `y_val` and `y_score` equal to `prob_modelKNN[:, 1]`. Assign the results to `fpr_modelKNN`, `tpr_modelKNN` and `thresholds_modelKNN`. <br>\n",
    "2) Repeat the same procedure to the remaining models, changing the names of the objects accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba9cc5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_modelKNN, tpr_modelKNN, thresholds_modelKNN = roc_curve(y_true = y_val, y_score = prob_modelKNN[:,1])\n",
    "fpr_modelDT, tpr_modelDT, thresholds_modelDT = roc_curve(y_val, prob_modelDT[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f50603be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       inf, 1.        , 0.61538462, 0.57142857, 0.2739726 ,\n",
       "       0.1875    , 0.14634146, 0.125     , 0.01515152])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_modelDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2dbaaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([inf, 0.8, 0.6, 0.4, 0.2, 0. ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_modelKNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b57628",
   "metadata": {},
   "source": [
    "__`Step 29`__ The purpose of this step is to plot the roc curve associated to each model. Do the following instructions in only one single cell, so the three roc curves appear in the same visualization. <br>\n",
    "1) Create a plot using the function `plt.plot()`, where the data to be represented is going to be the `fpr_modelKNN`, `tpr_modelKNN`, and `label=\"ROC Curve KNN\"` <br>\n",
    "2) Similarly to the previous step, plot now the values regarding `modelDT` <br>\n",
    "3) Similarly to the previous step, plot now the values regarding `modelNN` <br>\n",
    "4) call the function plt.legend()\n",
    "5) Call the function plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8282be33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr_modelKNN, tpr_modelKNN,label=\"ROC Curve KNN\")\n",
    "plt.plot(fpr_modelDT, tpr_modelDT, label=\"ROC Curve DT\")\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f50748b",
   "metadata": {},
   "source": [
    "__CONCLUSION__ <br>\n",
    "- The decision tree seems to be the better model among the three tested algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00505289",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"13th-bullet\">\n",
    "\n",
    "#### 4.2.3.3. CHANGE THE THRESHOLD\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452405b7",
   "metadata": {},
   "source": [
    "At this point, you already know which are the best hyperparameters of your best model. <br>\n",
    "The last thing you can try out to improve the performance of your model is to change the threshold of what you consider a positive prediction vs a negative prediction. <br>\n",
    "By default, that threshold is 0.5, i.e., observations where the probability of being 1 is equal or higher to 0.5 are considered positive, otherwise negative.\n",
    "\n",
    "Like we did to plot the ROC Curve, in this case we are just going to use one partition, provided by the train_test_split on `Step 31.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c8877a",
   "metadata": {},
   "source": [
    "__`Step 30`__ Fit your final model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a5660eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = final_model_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f429101c",
   "metadata": {},
   "source": [
    "__`Step 31`__ Calculate the probabilities associated with each observation in X_val being of class 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b4bb472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85365854, 0.14634146],\n",
       "       [0.38461538, 0.61538462],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.8125    , 0.1875    ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.38461538, 0.61538462],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.38461538, 0.61538462],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.42857143, 0.57142857],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.42857143, 0.57142857],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.        , 1.        ],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.38461538, 0.61538462],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.38461538, 0.61538462],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.38461538, 0.61538462],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.42857143, 0.57142857],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.8125    , 0.1875    ],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.38461538, 0.61538462],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.42857143, 0.57142857],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.42857143, 0.57142857],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.38461538, 0.61538462],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.38461538, 0.61538462],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.38461538, 0.61538462],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.42857143, 0.57142857],\n",
       "       [0.8125    , 0.1875    ],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [0.7260274 , 0.2739726 ],\n",
       "       [0.98484848, 0.01515152]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba = final_model.predict_proba(X_val)\n",
    "predict_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d072b5",
   "metadata": {},
   "source": [
    "__`Step 32`__ The purpose of this step is to plot the precision recall curve associated to the best model. <br>\n",
    "1) Import precision_recall_curve from sklearn.metrics<br>\n",
    "2) Get the precision, the recall and the thresholds from your precision recall curve<br>\n",
    "3) Check what is the threshold for the best f1 score<br>\n",
    "4) Plot the precision recall curve and the best threshold.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "669476c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.146341, F-Score=0.396\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_val, predict_proba[:,1])\n",
    "\n",
    "# apply f1 score\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n",
    "\n",
    "plt.plot(recall, precision, marker='.', label='DT')\n",
    "plt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b47ce",
   "metadata": {},
   "source": [
    "__CONCLUSION__ <br>\n",
    "- By changing the threshold to 0.146341, we are able to improve the f1-score of our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856db498",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a class=\"anchor\" id=\"13th-bullet\">\n",
    "\n",
    "### 4.2.4. TEST THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eefd79",
   "metadata": {},
   "source": [
    "__`Step 33`__ We will now train the model with all available train data (not splitting into train and validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0713dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = keep_data.copy()\n",
    "\n",
    "X_train = keep_data.drop(['DepVar'], axis = 1)\n",
    "y_train = keep_data['DepVar']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f9cde2",
   "metadata": {},
   "source": [
    "__`Step 34`__ Apply all the needed transformations in your training data and your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f2f0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = transform_data(X_train, X_test, X_2nd_df_flag = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cd1f3a",
   "metadata": {},
   "source": [
    "__`Step 35`__ Train your final model in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca466134",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = final_model_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ddfe6",
   "metadata": {},
   "source": [
    "__`Step 36`__ Obtain the predictions of the probabilities of your final model in the test data by calling the method `predict()` and corresponding probabilities with `predict_proba()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49899c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.predict(X_test) # the method predict() will predict the classes of your target when the threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "817daa40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96585366, 0.03414634],\n",
       "       [0.7704918 , 0.2295082 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.60784314, 0.39215686],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.60784314, 0.39215686],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.60784314, 0.39215686],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.7704918 , 0.2295082 ],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.7704918 , 0.2295082 ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.7704918 , 0.2295082 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.07692308, 0.92307692],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.7704918 , 0.2295082 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [0.07692308, 0.92307692],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.7704918 , 0.2295082 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.7704918 , 0.2295082 ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.60784314, 0.39215686],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.60784314, 0.39215686],\n",
       "       [0.7704918 , 0.2295082 ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.7704918 , 0.2295082 ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.36666667, 0.63333333],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.7704918 , 0.2295082 ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96585366, 0.03414634],\n",
       "       [0.96585366, 0.03414634]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba_test = final_model.predict_proba(X_test)\n",
    "predict_proba_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef85aed",
   "metadata": {},
   "source": [
    "__`Step 37`__ Define your final predictions, by changing the threshold of what is accepted as 1 and as 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "431c42ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = []\n",
    "\n",
    "for value in predict_proba_test[:,1]:\n",
    "    if (value>=0.146341):\n",
    "        test_pred.append(1)\n",
    "    else:\n",
    "        test_pred.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fa98cb",
   "metadata": {},
   "source": [
    "__`Step 38`__ Compute model final score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3683abdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05381828",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"14th-bullet\">\n",
    "\n",
    "# 5. Deploy\n",
    "\n",
    "</a>\n",
    "<img src=\"Images/step5.png\" style=\"height:70px\">\n",
    "\n",
    "\n",
    "You used the previous steps of modelling and assessment to determine what would be best strategies when it comes to preprocessing, scaling, feature selection, algorithm and hyper-parameters you could find. \n",
    "\n",
    "**By this stage, all of those choices were already made**. For that reason, a split between training and validation is no longer necessary. **A good practice** would be to take the initial data and train a final model with all of the labeled data that you have available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2bd53841",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'Data/keep_data.csv')\n",
    "\n",
    "X_train = train.drop(['DepVar'], axis = 1)\n",
    "y_train = train['DepVar']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e21a2d",
   "metadata": {},
   "source": [
    "**Everything is figured by this stage**, so, on a first level all you need to do is replicate the exact preprocessing, scaling and feature selection decisions you made before.<br>\n",
    "When it comes to the final model, all you have to do is creeate a new instance of your best algorithm with the best parameters that you uncovered (no need to try all algorithms and hyper-parameters again)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2aa065",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<a class=\"anchor\" id=\"15th-bullet\">\n",
    "\n",
    "## 5.1. Import your test data and apply transformations\n",
    "    \n",
    "</a>\n",
    "    \n",
    "</div>\n",
    "\n",
    "__`Step 33`__ Remember, the test data does not have the `outcome` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6fa60546-f1ab-4530-94a2-48c61c5f057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel(r'Data/test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b0d4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel(r'Data/test.xlsx')\n",
    "test = test[['Custid','Mnt','Clothes','NetPurchase','Marital_Status']].copy() # now we have all the columns needed\n",
    "test.set_index(['Custid'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991627c",
   "metadata": {},
   "source": [
    "__`Step 34`__ Apply all the needed transformations in your training data and your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c4e8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = transform_data(X_train, test, X_2nd_df_flag = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939879dd",
   "metadata": {},
   "source": [
    "__`Step 35`__ Train your final model in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2e28ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = final_model_dt.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d07b44",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<a class=\"anchor\" id=\"17th-bullet\">\n",
    "\n",
    "## 5.2. Obtain Predictions on the test data from your final model\n",
    "    \n",
    "</a>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de773822",
   "metadata": {},
   "source": [
    "__`Step 36`__ Obtain the predictions of the probabilities of your final model in the test data. by calling the method `predict_proba()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b912c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.predict(test) # the method predict() will predict the classes of your target when the threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19a3096d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.59615385, 0.40384615],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.37037037, 0.62962963],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.95807128, 0.04192872],\n",
       "       [0.89380531, 0.10619469],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.79130435, 0.20869565],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147],\n",
       "       [0.99620853, 0.00379147]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba_test = final_model.predict_proba(test)\n",
    "predict_proba_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4917b45",
   "metadata": {},
   "source": [
    "__`Step 37`__ Define your final predictions, by changing the threshold of what is accepted as 1 and as 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf0905ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = []\n",
    "\n",
    "for value in predict_proba_test[:,1]:\n",
    "    if (value>=0.146341):\n",
    "        final_pred.append(1)\n",
    "    else:\n",
    "        final_pred.append(0)\n",
    "\n",
    "final_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4effcd3a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "<a class=\"anchor\" id=\"18th-bullet\">\n",
    "\n",
    "## 5.3. Create a Dataframe containing the index of each row and its intended prediction and export it to a csv file\n",
    "    \n",
    "</a>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81623199",
   "metadata": {},
   "source": [
    "__`Step 38`__ Create a new DataFrame, and add as column `Custid` the values of the `Custid` for each customer in the test data set, and a column named `DepVar` where you will store the preditions of your final model in the test data. Save those results in a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd0983e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Custid</th>\n",
       "      <th>DepVar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1555</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5664</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7457</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6479</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Custid  DepVar\n",
       "0     7770       0\n",
       "1     3170       0\n",
       "2    10875       1\n",
       "3     6213       0\n",
       "4     4345       0\n",
       "5    10407       1\n",
       "6     4150       0\n",
       "7     1555       0\n",
       "8     5664       1\n",
       "9     9408       0\n",
       "10    2696       0\n",
       "11    3936       1\n",
       "12    8247       0\n",
       "13    2631       0\n",
       "14    7436       0\n",
       "15   10975       0\n",
       "16   10797       0\n",
       "17    7457       0\n",
       "18   10246       0\n",
       "19    6479       0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = pd.DataFrame()\n",
    "answer['Custid'] = test.index\n",
    "answer['DepVar'] = final_pred\n",
    "answer.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ff44ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DepVar\n",
       "0    432\n",
       "1     68\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer['DepVar'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "551b60d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.to_csv('answer.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
