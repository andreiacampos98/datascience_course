{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/picture1.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "\n",
    "### Table of Contents\n",
    "* [0. Identify Business needs](#business)<br>\n",
    "* [1. Import Data](#import) <br>\n",
    "    * [1.1. Import the needed libraries](#lib)<br>\n",
    "    * [1.2. Import and integrate data](#integrate)<br>\n",
    "    * [1.3. Set index](#index)<br>\n",
    "    * [1.4. Check for duplicates](#duplicates)<br>\n",
    "* [2. Explore Data](#explore) <br>\n",
    "    * [2.1. Basic Exploration](#basic)<br>\n",
    "    * [2.2. Statistical Exploration](#stats)<br>\n",
    "        * [2.2.1. Numerical Variables](#stats_num)<br>\n",
    "        * [2.2.2. Categorical Variables](#stats_cat)<br>\n",
    "    * [2.3. Visual Exploration](#visual)<br>\n",
    "        * [2.3.1. Numerical Variables](#visual_num)<br>\n",
    "        * [2.3.2. Categorical Variables](#visual_cat)<br>\n",
    "    * [2.4. In-depth Exploration](#depth)<br>\n",
    "* [3. Preprocess Data](#preprocess) <br>\n",
    "    * [3.1. Data Cleaning](#clean)<br>\n",
    "        * [3.1.1. Outliers](#outliers)<br>\n",
    "        * [3.1.2. Missing Values](#missing)<br>\n",
    "    * [3.2. Data Transformation](#transform)<br>\n",
    "        * [3.2.1. Create new variables](#new)<br>\n",
    "        * [3.2.2. Misclassifications](#misc)<br>\n",
    "        * [3.2.3. Incoherencies](#inco)<br>\n",
    "        * [3.2.4. Binning](#bin)<br>\n",
    "        * [3.2.5. Reclassify](#rec)<br>\n",
    "        * [3.2.6. Power Transform](#power)<br>\n",
    "        * [3.2.7. Apply ordinal encoding and create Dummy variables](#dummy)<br>\n",
    "        * [3.2.8. Scaling](#scale)<br>\n",
    "    * [3.3. Data Reduction](#reduce)<br>\n",
    "        * [3.3.1. Multicollinearity - Check correlation](#corr)<br>\n",
    "        * [3.3.2. Unary Variables](#unary)<br>\n",
    "        * [3.3.3. Variables with a high percentage of missing values](#na)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/process_ML.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<a id='business'>\n",
    "<font color = '#006400'> \n",
    "    \n",
    "# 0. Identify Business needs </font>\n",
    "</a>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to identify well the business needs.\n",
    "\n",
    "• TugasRWe is a Portuguese retailer offering an assortment of goods within 5 major categories: Clothes, Housekeeping,\n",
    "kitchen, small appliances and toys. <br><br>\n",
    "• Tugas started a loyalty program 2 years ago. Among other objectives, the program’s aim is to gather Customer information\n",
    "to better drive the marketing efforts. <br><br>\n",
    "• There is enough historical information to start producing sound knowledge about their Customer database. IT extracted two files (at Customer Level) to be used by the analytical team. <br>\n",
    "\n",
    "__Demographic.xlsx__\n",
    "\n",
    "| Attribute | Description | \n",
    "| --- | --- |\n",
    "| Custid | Unique identification of the customer |\n",
    "| Year_Birth | Customer Year of Birth |\n",
    "| Gender | Costumer Gender |\n",
    "| Education | Costumer Education |\n",
    "| Marital_Status | Costumer Marital Status |\n",
    "| Dependents | Dependents (Yes = 1) |\n",
    "| Income | Costumer Household Income |\n",
    "| Country | Costumer's Country |\n",
    "| City | Costumer's City |\n",
    "\n",
    "\n",
    "__Firmographic.csv__\n",
    "\n",
    "| Attribute | Description | \n",
    "| --- | --- |\n",
    "| Custid | Unique identification of the customer |\n",
    "| Rcn | Recency in days |\n",
    "| Frq | Total Number of Purchases |\n",
    "| Mnt | Total Amount spent on Purchases |\n",
    "| Clothes | % Amount spent on clothes |\n",
    "| Kitchen | % Amount spent on kitchen products |\n",
    "| SmallAppliances | % Amount spent on small appliances |\n",
    "| HouseKeeping | % Amount spent on housekeeping products |\n",
    "| Toys | % Amount spent on toys |\n",
    "| NetPurchase | % Purchases through the net channel |\n",
    "| StorePurchase | % Purchases through the store |\n",
    "| Recomendation | Recomendation [1-5] |\n",
    "| Credit_Card | Information about Costumer Credit Card - Flag variable|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BACK TO TOC](#toc)\n",
    "    \n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<a id='import'>\n",
    "<font color = '#006400'> \n",
    "    \n",
    "# 1. Import Data </font>\n",
    "</a>\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<a id='lib'></a>\n",
    "\n",
    "## 1.1. Import the needed libraries\n",
    "    \n",
    "</div>\n",
    "\n",
    "__`Step 1`__ Import the following libraries/functions: <br>\n",
    "- pandas as pd <br>\n",
    "    - <font color=#7a8a7c>_Pandas is a Python library for data manipulation and analysis, providing easy-to-use data structures and data analysis tools_</font>\n",
    "- numpy as np <br>\n",
    "    - <font color=#7a8a7c>_NumPy is a Python library for numerical computing that provides efficient arrays and matrices operations, as well as mathematical functions for arrays._</font>\n",
    "- pyplot from matplotlib as plt <br>\n",
    "    - <font color=#7a8a7c>_Matplotlib is a Python library for creating high-quality visualizations, including line plots, scatter plots, bar plots, and more, with extensive customization options._</font>\n",
    "- seaborn as sns<br>\n",
    "    - <font color=#7a8a7c>_Seaborn is a Python library for data visualization based on Matplotlib, providing additional high-level interface for creating informative statistical graphics with ease._</font>\n",
    "    \n",
    "    \n",
    "We are going also to import some tools from sklearn: <br>\n",
    "<font color=#7a8a7c>_Scikit-learn (sklearn) is a Python library for machine learning, providing a wide range of supervised and unsupervised learning algorithms, as well as tools for data preprocessing, model selection, and evaluation._</font>\n",
    "- MinMaxScaler from sklearn.preprocessing<br>\n",
    "- KNNImputer from from sklearn.impute<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<a id='integrate'></a>\n",
    "\n",
    "## 1.2. Import and integrate data\n",
    "    \n",
    "</div>\n",
    "\n",
    "__`Step 2`__ Import the excel file `demographic.xlsx` and store it in the object `demo` <br>\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 3`__ Import the csv file `firmographic.csv` and store it in the object `firmo`<br>\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if your variables are not separated by a ',', you can define the delimiter used by defining the parameter sep\n",
    "# for example, in case of ';', you should use: firmo = pd.read_csv('firmographic.csv', sep = ';') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 4`__ Merge the data from the two previous files and store it in the object `df`. By default, the merge uses the method \"inner join\". <br>\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html\n",
    "\n",
    "<font color=#7a8a7c>_Merge method in pandas is used to combine two or more dataframes into a single dataframe, based on common columns or indices, using various types of joins._</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<a id='index'></a>\n",
    "\n",
    "## 1.3. Set Index \n",
    "    \n",
    "</div>\n",
    "\n",
    "__`Step 5`__ Define the variable \"Custid\" as the index of the dataframe using the method `set_index()`.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<a id='duplicates'></a>\n",
    "\n",
    "## 1.4. Check for duplicates\n",
    "    \n",
    "</div>\n",
    "\n",
    "__`Step 6`__ Check for duplicated rows with `duplicated()` and drop any duplicate rows present in the dataframe with the method `drop_duplicates()`\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html <br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BACK TO TOC](#toc)\n",
    "    \n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<a id='explore'>\n",
    "<font color = '#006400'> \n",
    "    \n",
    "# 2. Explore Data </font>\n",
    "</a>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<a id='basic'></a>\n",
    "\n",
    "## 2.1. Basic Exploration\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 7`__ Check the number of rows and columns in the dataset using the attribute `shape`\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains 2500 rows and 20 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 8`__ Check the name of the columns of our dataset using the attribute `columns`\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.columns.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 9`__ Check the first three rows of the dataset using the method `head()`\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way, you have the method `tail()` that return the last rows of the dataset.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 10`__ Get more information of the dataset by calling the method `info()`\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that we are working with:\n",
    "- 3 float variables\n",
    "- 11 integer variables\n",
    "- 6 object variables\n",
    "\n",
    "We can also check that some of the variables have missing values. We are going to deal with this in a further step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<a id='stats'></a>\n",
    "\n",
    "## 2.2. Statistical Exploration\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<a id='stats_num'></a>\n",
    "\n",
    "### 2.3.1. Numerical Variables\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 11`__ Get the main descriptive statistics for all the numeric variables in using the method `describe()`\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, we can get some conclusions. Some examples are:\n",
    "- `count`- The income variable has 2431 valid values. We have a problem of missing values in here.\n",
    "- `mean`- In average, my customers spent on my store 654 monetary units;\n",
    "- `std`- The standard deviation of Income is quite high. This indicates that the values are spread out over a wider range.\n",
    "- `min`- All the customers have bought in my store at least 3 times.\n",
    "- `50%`- Half of my customers spend till 402 monetary units on my store.\n",
    "- `max`- The maximum value for recommendation is 6. This is an incoherence - according to the business needs, the range is between 1 and 5.\n",
    "\n",
    "The `describe()` method provides the main descriptive statistics: count, mean, standard deviation, minimum value, 25 percentile, 50 percentile or median, 75 percentile and maximum value. \n",
    "<br>\n",
    "However, you can call directly other measures, such as the skewness or the kurtosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 12`__ Get the skewness associated with each variable in the dataset using the method `skew()`\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.skew.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concerning the variables' skewness, we can conclude the following:\n",
    "- `Moderate skewness (between |0.5| and |1.0|)`: Dependents, Frq, Mnt, \n",
    "- `High skewness (higher than |1.0|)`: Rcn, Kitchen, HouseKeeping, Toys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 13`__ Get the kurtosis associated with the variables using the method `kurt()`\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High kurtosis in a data set is an indicator that data has heavy tails or outliers. A standard normal distribution has a kurtosis of 3, so values higher than that could indicate presence of outliers. <br>\n",
    "\n",
    "We need to check further about the presence of possible outliers for the variables:\n",
    "- Rcn\n",
    "- Kitchen\n",
    "- HouseKeeping\n",
    "- Toys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<a id='stats_cat'></a>\n",
    "\n",
    "### 2.3.2. Categorical Variables\n",
    "    \n",
    "</div>\n",
    "\n",
    "__`Step 14`__ Get the main descriptive statistics for all the categorical variables in using the method `describe(include = ['O'])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify some problems or issues that we need to address before applying a model:\n",
    "- We have 3 possible values for Gender, 6 for Education and 9 for Marital Status: we need to check further if all those values are acceptable;\n",
    "- The variable country is unary - we only have one possible value;\n",
    "- The variable city has also one possible value and it has only 73 rows filled. Maybe we should drop this variable.\n",
    "- The credit card has only 67 values out of 2500 filled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 15`__ Check the levels/possible values in the variables \"Gender\", \"Education\", \"Marital_Status\", \"Country\", \"City\" and \"Credit Card\" using the method `value_counts()`\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Gender`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 5 observations with a value of \"?\". We need to change this value, since it is not a valid value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Education`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some problems in this variable: <br>\n",
    "- OldSchool is not a valid value;<br>\n",
    "- Not clear what is 2n Cycle and Basic Education. <br>\n",
    "      \n",
    "We need to make some transformations in this variable also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Marital Status`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that this variable needs also some transformations: <br>\n",
    "- Together, Married and Divorced are written sometimes using capital letters;<br>\n",
    "- BigConfusion is not a valid value;<br>\n",
    "- Does it make sense to have Together and Married into two different levels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Country`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In country, there are no missing values, but the value is always the same. It does not make sense to keep this variable to the modelling phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`City`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In city, we have a significant quantity of values that are missing, and the city is always the same. Assuming that there is no reason behind the missingness on this variable, we are going to delete this variable in a further step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Credit Card`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the variable Credit Card, we also have a significant number of missing values. Assuming that there is a reason behind the missingness, we are going to fill all the missing values with a constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<a id='visual'></a>\n",
    "\n",
    "## 2.3. Visual Exploration\n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<a id='visual_num'></a>\n",
    "\n",
    "### 2.3.1. Numerical Variables\n",
    "    \n",
    "</div>\n",
    "\n",
    "__`Step 16`__ Check the distribution of the variable 'Mnt' using a `histplot()`. Define the color as green and the number of bins equal to 10.\n",
    "\n",
    "https://seaborn.pydata.org/generated/seaborn.histplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 17`__ Create a `scatterplot` where the x axis represent the Income and the y axis define the Mnt spent for each customer using `seaborn`.\n",
    "\n",
    "https://seaborn.pydata.org/generated/seaborn.scatterplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that the higher the Income, the higher the monetary spent on our store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 17.B`__ This time, create a scatterplot similar to the previous one, but with the following changes:\n",
    "- Define a figure with size equal to (12,8), and composed by two axes.\n",
    "- The first axe is going to contain a scatterplot similar to the one on the previous step-\n",
    "- The second axe will display a scatterplot where the x axis will define the Income and the y axis will represent the Mnt. Use the parameter hue to represent a third variable, the recomendation.\n",
    "- Define the lower limit of y as -200\n",
    "- Define the lower limit of x as 0\n",
    "- Define the ticks of the x axis between 0 and 160000, in steps of 30000\n",
    "- Define the title of the plot as \"Income vs Monetary vs Recomendation\", with a fontsize of 16 and a blue color\n",
    "- The legend of the plot should be on the upper left area and the title of the legend should be \"Recomendation\"\n",
    "- Define the label of the x axis as \"Customer's Income\"\n",
    "- Remove the top and right axis of the plot\n",
    "- Save the figure as \"my_plot.png\", with a resolution of 300 dots per inch and with no background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the figure as (12,8)\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (12,8))\n",
    "\n",
    "# create first plot without changes, similar to step 17\n",
    "sns.scatterplot(ax = ax1, data = df, x = 'Income', y = 'Mnt')\n",
    "\n",
    "# create second plot with changes\n",
    "sns.scatterplot(ax = ax2, data = df, x = 'Income', y = 'Mnt', hue = 'Recomendation')\n",
    "\n",
    "# define the limits of y axis using matplotlib.pyplot.ylim\n",
    "plt.ylim(-200,None)\n",
    "# define the limits of x axis using matplotlib.pyplot.xlim\n",
    "plt.xlim(0,None)\n",
    "\n",
    "# define the ticks in x axis using matplotlib.pyplot.xticks(start, stop, step)\n",
    "# np.arange - Return evenly spaced values within a given interval.\n",
    "plt.xticks(np.arange(0,160000,30000))\n",
    "\n",
    "# define the title using matplotlib.pyplot.title\n",
    "plt.title('Income vs Monetary vs Recomendation', fontsize= 14, color = 'black')\n",
    "\n",
    "# define the legend using matplotlib.pyplot.legend\n",
    "plt.legend(loc = 'upper left', title = 'Recomendation', frameon = False)\n",
    "\n",
    "# define the label for x axis using matplotlib.pyplot.xlabel\n",
    "plt.xlabel(\"Customer's Income\")\n",
    "plt.ylabel(\"Monetary spent\")\n",
    "\n",
    "# Remove the top and right axis of the plot\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "\n",
    "# Save the figure as \"my_plot.png\", with a resolution of 300 dots per inch and with no background.\n",
    "plt.savefig('my_plot.png', dpi = 300, transparent = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 18`__ Plot the pairwise relationships of the variables \"Clothes\", \"Toys\" and \"HouseKeeping\" using a `pairplot`\n",
    "\n",
    "https://seaborn.pydata.org/generated/seaborn.pairplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 19`__ Check the spearman correlation between numerical variables using the method `corr(method = 'spearman')`.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html <br>\n",
    "https://seaborn.pydata.org/generated/seaborn.heatmap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that NetPurchase and StorePurchase have a perfect negative correlation. We don't need both variables. We are going to remove one of them in __`Step 41 `__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a id='visual_cat'></a>\n",
    "    \n",
    "### 2.3.2. Categorical Variables\n",
    "\n",
    "</div>\n",
    "\n",
    "__`Step 20`__ Show the counts of observations in each categorical bin using bars for the variable \"Marital_Status\" using a `countplot()`.\n",
    "Define the hue as \"Gender\". Show only the counting for Single, Divorced, Widow, Married and Together in this order.\n",
    "\n",
    "https://seaborn.pydata.org/generated/seaborn.countplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 21`__ Draw a scatterplot between Income (numerical variable) and Education (categorical variable) using the `stripplot()`\n",
    "\n",
    "https://seaborn.pydata.org/generated/seaborn.stripplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot see significant differences on the money earned depending on the Education level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<a id='depth'></a>\n",
    "\n",
    "## 2.4. In-depth Exploration\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go further and try to understand better our population of study using the methods `groupby()` and `query()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 22`__ What is the mean value of `Mnt` when `Dependents` is equal to 0? And when is equal to 1? Use `groupby()`.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html <br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 23`__ What is the median value of `Mnt` spent by female customers when `Dependents` is equal to 0? And when is equal to 1? Use `query()`\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.median.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BACK TO TOC](#toc)\n",
    "    \n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<a id='preprocess'>\n",
    "<font color = '#006400'> \n",
    "    \n",
    "# 3. Preprocess Data </font>\n",
    "</a>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<a id='clean'></a>\n",
    "\n",
    "## 3.1. Data Cleaning\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a id='outliers'></a>\n",
    "\n",
    "### 3.1.1. Outliers\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In __Step 13__ we understood that the variables \"Rcn\",  \"Kitchen\", \"HouseKeeping\" and \"Toys\", due to the high kurtosis, could have potential outliers. In the following steps we are going to investigate further this possible situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 24`__ Create a figure with two axes, where the boxplots of the variables \"Rcn\" and \"Kitchen\" are shown. Use the `boxplot()` from seaborn. \n",
    "\n",
    "https://seaborn.pydata.org/generated/seaborn.boxplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize = (14,6))\n",
    "sns.boxplot(ax = ax1, data = df, x = 'Rcn')\n",
    "sns.boxplot(ax = ax2, data = df, x = 'Kitchen')\n",
    "sns.boxplot(ax = ax3, data = df, x = 'HouseKeeping')\n",
    "sns.boxplot(ax = ax4, data = df, x = 'Toys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 25`__ Create a figure with two axes, where the histplots of the variables \"Rcn\" and \"Kitchen\" are shown. Use the `histplot()` from seaborn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 26`__ Remove the observations where \n",
    "\n",
    "- Kitchen is higher than 50 or \n",
    "- Toys is higher than 50 <br> \n",
    "\n",
    "using the method `drop()`.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a id='missing'></a>\n",
    "\n",
    "### 3.1.2. Missing Values\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 27`__ Check how many missing values you have in the dataset using `isna().sum()`\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html <br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2.1 Fill with constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 28`__ Fill the missing values in `Credit_Card` with the constant \"Missing\" using the method `fillna()`.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm, using using the method `value_counts()`, that the variable `Credit_Card` has no more missing values.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2.2 Fill with mean / median / mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 29`__ Fill the missing values in Marital Status and Education with the mode and in Income with median using `fillna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that these 3 variables have no missing values anymore using `isna().sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2.2 Fill with KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 30`__ Use a predictive model to fill the missing values in Clothes. You can use the variables Kitchen, SmallAppliances, HouseKeeping and Toys, that have a correlation of -0.7 with clothes, to fill the missing values with KNNImputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = df[['Clothes','Kitchen','SmallAppliances','HouseKeeping','Toys']]\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=1)\n",
    "array_impute = imputer.fit_transform(df_products) # this is an array\n",
    "df_products = pd.DataFrame(array_impute, columns = df_products.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clothes'] = df_products['Clothes'].values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BACK TO TOC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<a id='transform'></a>\n",
    "\n",
    "## 3.2. Data Transformation\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a id='new'></a>\n",
    "\n",
    "### 3.2.1. Create new variables\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 31`__ Create the variable \"Age\" from the \"Year_Birth\". Tip: check the method `date.today()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 32`__ Create a new variable where the purpose is to understand how much money a customer spend on my store each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a id='misc'></a>\n",
    "\n",
    "### 3.2.2. Misclassifications\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 33`__ Review the counting for possible values in the Gender variable using `value_counts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 33.B`__ Replace the \"?\" with the most frequent value using `mode()[0]`, which is going to return the most frequent value.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 34`__ Review the counting for possible values in the `Marital_Status` variable with `value_counts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 34.B`__ Change \"TOGETHER\" to \"Together\" and do the same (Capitalize the words) for \"DIVORCED\" and \"MARRIED\" using `str.capitalize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 34.C`__ Replace the \"BigConfusion\" with the most frequent value. Apply the same procedure as in `Gender`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 35`__ Review the counting for possible values in the `Education` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 35.B`__ Replace the \"OldSchool\" with the most frequent value with `mode()[0]`. Apply the same procedure as in `Gender` and `Marital_Status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a id='inco'></a>\n",
    "\n",
    "### 3.2.3. Incoherencies\n",
    "    \n",
    "</div>\n",
    "\n",
    "__`Step 36`__ Check possible incoherencies in your data. One situation that is impossible to happen is to have values of frequency equal to 0 when there was some money spent by the customer. Are there any such incoherences? If yes, change those values of Frequency to 1.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a id='bin'></a>\n",
    "\n",
    "### 3.2.4. Binning\n",
    "    \n",
    "</div>\n",
    "\n",
    "__`Step 37`__ Create a new variable named as \"Income_bins\" where Income is going to be represented in thre possible values - \"Low\", \"Medium\" and \"High\". By using the method `cut()`, those are going to be equal-width bins.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.cut.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a id='rec'></a>\n",
    "\n",
    "### 3.2.5. Reclassify\n",
    "    \n",
    "</div>\n",
    "\n",
    "__`Step 38`__ Due to the similarity of the classification, change the value \"Together\" to \"Married\" in Marital_Status using the method `replace()`.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 39`__ Since we are not sure about what 2nd Cycle and Basic School means, we are going to create a new binary variable called `Higher_Educ` where if the customer has higher education we assign the value 1, and 0 otherwise. One option is to explore the numpy method `np.where()`\n",
    "Remove the variable `Education`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a id='power'></a>\n",
    "\n",
    "### 3.2.6. Power Transform\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 40`__ Create a new variable `sqrt_rcn` and `sqrt_mnt` by applying a square root transformation to the variable `Rcn` and `Mnt`, in order to try to normalize the variables. Use the numpy method `np.sqrt()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 40.B`__ Compare the distribution of the variables with and without sqrt tranformation with a histplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying scaling in our final dataset, we are going to remove some features that could lead to problems on modelling or even on the scaling.\n",
    "\n",
    "[BACK TO TOC](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<a id='reduce'></a>\n",
    "\n",
    "## 3.3. Data Reduction \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a id='corr'></a>\n",
    "\n",
    "### 3.3.1. Multicollinearity - Check correlation\n",
    "    \n",
    "</div>\n",
    "\n",
    "We understood in __Step 19__, using the heatmap to check the spearman correlation between the variables, that NetPurchase had a perfect negative relationship with StorePurchase. We don't need both, so we are going to remove one of those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 41`__ Drop the variable `NetPurchase`, since it is highly correlated with `StorePurchase`. Do the same with `Year_Birth`, since we used this variable to calculate `Age` and they are highly correlated using `drop()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a id='unary'></a>\n",
    "\n",
    "### 3.3.2. Unary Variables\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 42`__ Drop the variable `Country`, since it is an unary variable with `drop()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a id='na'></a>\n",
    "\n",
    "### 3.3.3. Variables with a high percentage of missing values\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 43`__ Drop the variable `City`, since it has 97% of the values missing. Try using `dropna()`, defining the thresh parameter as 90% of the lenght of our dataset\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## 3.2. Back to Data Transformation\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a id='dummy'></a>\n",
    "\n",
    "### 3.2.7. Apply ordinal encoding and create Dummy variables\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 44`__ For the variable `Income_bins` where we have an order, we are going to apply ordinal encoding. Define the low value to 0, medium to 1 and high to 2 using the method `replace()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 44.B`__ We can see from the `info()` of the dataset that \"Income_bins\" is now a category. Convert this variable into an integer using `astype()` and check the new data type with the attribute `dtype`.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 45`__ For the categorical variables, apply `get_dummies()`.\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<a id='scale'></a>\n",
    "\n",
    "### 3.2.8. Scaling\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 46`__ Scale the data using `MinMaxScaler()` in the range [0,1]. Check how `KNNImputer()` was applied. `MinMaxScaler()` implementation is very similar.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
